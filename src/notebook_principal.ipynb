{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e76089",
   "metadata": {},
   "source": [
    "# PR√ÅCTICA B2-2 #\n",
    "\n",
    "## M√ìDULO DE GESTI√ìN DE RIESGOS ##\n",
    "### Escenarios de Estr√©s y Cambios de R√©gimen de Mercado ###\n",
    "\n",
    "### Datos b√°sicos: ###\n",
    "- Pr√°ctica en grupos de dos personas\n",
    "- Entrega el d√≠a 15 de febrero a trav√©s del aula virtual.\n",
    "- Los entregables son un notebook de Python y un resumen ejecutivo en formato PDF.\n",
    "\n",
    "### Objetivo de la pr√°ctica ###\n",
    "El objetivo de esta pr√°ctica es redise√±ar un motor de stress testing en Python capaz de\n",
    "capturar el riesgo de cola y los cambios de r√©gimen, identificar cu√°ndo el mercado entra en\n",
    "‚Äúcrisis‚Äù y cuantificar el riesgo real cuando la diversificaci√≥n desaparece. El motor de\n",
    "simulaci√≥n deber√° utilizarse expl√≠citamente para construir Escenarios de Estr√©s cuyo\n",
    "objetivo sea ‚Äúromper la cartera‚Äù, forzando condiciones adversas y econ√≥micamente\n",
    "coherentes, y cuantificando p√©rdidas extremas mediante VaR del 99% y Expected Shortfall\n",
    "(CVaR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8791c8",
   "metadata": {},
   "source": [
    "### Fase 0 - Preparacion y Estructura del Proyecto ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7aae98",
   "metadata": {},
   "source": [
    "### Librerias ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ff28ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from hmmlearn import hmm\n",
    "from pandas_datareader import data as pdr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats as sp_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9658f1ef",
   "metadata": {},
   "source": [
    "### Variables ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6e2898",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "BASE_DIR = Path(\"..\").resolve()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "DATA_BRONZE_DIR = DATA_DIR / \"bronze\"\n",
    "DATA_SILVER_DIR = DATA_DIR / \"silver\"\n",
    "DATA_GOLD_DIR = DATA_DIR / \"gold\"\n",
    "FIGURES_DIR = BASE_DIR / \"figures\"\n",
    "REPORT_DIR = BASE_DIR / \"report\"\n",
    "\n",
    "START_DATE = \"2006-01-01\"\n",
    "END_DATE = date.today().isoformat()\n",
    "\n",
    "COMBINED_PATH = DATA_GOLD_DIR / \"market_data_combined.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ed2b4",
   "metadata": {},
   "source": [
    "### Clases ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "75b0ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MarketData:\n",
    "    \"\"\"Utility class for downloading and combining market data.\"\"\"\n",
    "\n",
    "    equities: List[str] = field(default_factory=list)\n",
    "    yields: List[str] = field(default_factory=list)\n",
    "\n",
    "    combined_data: pd.DataFrame = field(init=False)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        equity_data = (\n",
    "            self.fetch_equities(self.equities, start=START_DATE, end=END_DATE)\n",
    "            if self.equities\n",
    "            else pd.DataFrame()\n",
    "        )\n",
    "        yield_data = (\n",
    "            self.fetch_us_yields(self.yields, start=START_DATE, end=END_DATE)\n",
    "            if self.yields\n",
    "            else pd.DataFrame()\n",
    "        )\n",
    "        self.combined_data = self.combine_and_fill(equity_data, yield_data)\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_equities(tickers: List[str], start: str, end: str) -> pd.DataFrame:\n",
    "        \"\"\"Fetch adjusted close prices for a list of tickers using yfinance.\"\"\"\n",
    "        if not tickers:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        equities = yf.download(\n",
    "            tickers,\n",
    "            start=start,\n",
    "            end=end,\n",
    "            progress=False,\n",
    "            threads=True,\n",
    "            auto_adjust=True,\n",
    "        )[\"Close\"]\n",
    "\n",
    "        if isinstance(tickers, list):\n",
    "            tickers_join = \"_\".join(tickers)\n",
    "        else:\n",
    "            tickers_join = str(tickers)\n",
    "\n",
    "        DATA_BRONZE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        equities_path = DATA_BRONZE_DIR / f\"equities_adj_close_{tickers_join}.csv\"\n",
    "        equities.sort_index().to_csv(equities_path)\n",
    "\n",
    "        return equities.sort_index()\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_us_yields(tickers: Union[List[str], str], start: str, end: str) -> pd.DataFrame:\n",
    "        \"\"\"Fetch US yields from FRED.\"\"\"\n",
    "        if not tickers:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        yields = pdr.DataReader(tickers, \"fred\", start, end)\n",
    "        yields.index = pd.to_datetime(yields.index)\n",
    "\n",
    "        if isinstance(tickers, list):\n",
    "            tickers_join = \"_\".join(tickers)\n",
    "        else:\n",
    "            tickers_join = str(tickers)\n",
    "\n",
    "        DATA_BRONZE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        yields_path = DATA_BRONZE_DIR / f\"us_yields_{tickers_join}.csv\"\n",
    "        yields.sort_index().to_csv(yields_path)\n",
    "\n",
    "        return yields.sort_index()\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_and_fill(equities: pd.DataFrame, yields: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Combine equities and yields into a single DataFrame and forward-fill missing yield data.\"\"\"\n",
    "        combined = pd.concat([equities, yields], axis=1).sort_index()\n",
    "\n",
    "        # Forward-fill only yield series to avoid contaminating equity prices\n",
    "        for col in [\"GS10\", \"GS2\", \"BAMLH0A0HYM2\"]:\n",
    "            if col in combined.columns:\n",
    "                combined[col] = combined[col].ffill()\n",
    "\n",
    "        DATA_SILVER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        combined_path = DATA_SILVER_DIR / \"market_data_combined.csv\"\n",
    "        combined.to_csv(combined_path)\n",
    "\n",
    "        return combined\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Portfolio:\n",
    "    \"\"\"Equal-weight portfolio built from equities and yield instruments.\"\"\"\n",
    "\n",
    "    assets: Dict[str, str]\n",
    "\n",
    "    prices: pd.DataFrame = field(init=False)\n",
    "    returns: pd.DataFrame = field(init=False)\n",
    "    weights: pd.DataFrame = field(init=False)\n",
    "    portfolio_returns: pd.Series = field(init=False)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self._load_prices()\n",
    "        self._compute_returns()\n",
    "        self._compute_dynamic_weights()\n",
    "        self._compute_portfolio_returns()\n",
    "\n",
    "    def _load_prices(self) -> None:\n",
    "        equities = [\n",
    "            ticker for ticker, asset_type in self.assets.items() if asset_type == \"equity\"\n",
    "        ]\n",
    "        yields = [\n",
    "            ticker for ticker, asset_type in self.assets.items() if asset_type == \"yield\"\n",
    "        ]\n",
    "\n",
    "        equity_data = MarketData.fetch_equities(equities, start=START_DATE, end=END_DATE)\n",
    "        yield_data = MarketData.fetch_us_yields(yields, start=START_DATE, end=END_DATE)\n",
    "\n",
    "        self.prices = MarketData.combine_and_fill(equity_data, yield_data)\n",
    "\n",
    "    def _compute_returns(self) -> None:\n",
    "        self.returns = self.prices.pct_change()\n",
    "\n",
    "    def _compute_dynamic_weights(self) -> None:\n",
    "        asset_exists = ~self.prices.isna()\n",
    "        n_assets = asset_exists.sum(axis=1)\n",
    "\n",
    "        self.weights = asset_exists.div(n_assets, axis=0).fillna(0.0)\n",
    "\n",
    "    def _compute_portfolio_returns(self) -> None:\n",
    "        self.portfolio_returns = (self.returns * self.weights).sum(axis=1)\n",
    "\n",
    "    def cumulative_return(self) -> pd.Series:\n",
    "        return (1 + self.portfolio_returns).cumprod()\n",
    "\n",
    "    def drawdown(self) -> pd.Series:\n",
    "        wealth = self.cumulative_return()\n",
    "        peak = wealth.cummax()\n",
    "        return (wealth - peak) / peak\n",
    "\n",
    "    def max_drawdown(self) -> float:\n",
    "        return float(self.drawdown().min())\n",
    "\n",
    "    def volatility(self, annualized: bool = True) -> float:\n",
    "        vol = float(self.portfolio_returns.std())\n",
    "        return vol * np.sqrt(252) if annualized else vol\n",
    "\n",
    "    def mean_return(self, annualized: bool = True) -> float:\n",
    "        mu = float(self.portfolio_returns.mean())\n",
    "        return mu * 252 if annualized else mu\n",
    "\n",
    "    def sharpe_ratio(self) -> float:\n",
    "        return self.mean_return() / self.volatility()\n",
    "\n",
    "    def var_cvar(self, alpha: float = 0.99) -> Tuple[float, float]:\n",
    "        var = float(self.portfolio_returns.quantile(1 - alpha))\n",
    "        cvar = float(self.portfolio_returns[self.portfolio_returns <= var].mean())\n",
    "        return var, cvar\n",
    "\n",
    "    def summary(self) -> pd.Series:\n",
    "        var_99, cvar_99 = self.var_cvar(0.99)\n",
    "\n",
    "        return pd.Series(\n",
    "            {\n",
    "                \"Mean Return (ann)\": self.mean_return(),\n",
    "                \"Volatility (ann)\": self.volatility(),\n",
    "                \"Sharpe\": self.sharpe_ratio(),\n",
    "                \"Max Drawdown\": self.max_drawdown(),\n",
    "                \"VaR 99%\": var_99,\n",
    "                \"CVaR 99%\": cvar_99,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def portfolio_composition_table(self) -> pd.DataFrame:\n",
    "        weights_pct = self.weights * 100\n",
    "        asset_values = self.prices * self.weights\n",
    "\n",
    "        data: Dict[Tuple[str, str], pd.Series] = {}\n",
    "        for asset in self.prices.columns:\n",
    "            data[(asset, \"weight_%\")] = weights_pct[asset]\n",
    "            data[(asset, \"price\")] = self.prices[asset]\n",
    "            data[(asset, \"value\")] = asset_values[asset]\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.columns = pd.MultiIndex.from_tuples(df.columns)\n",
    "\n",
    "        df[\"portfolio_value\"] = asset_values.sum(axis=1)\n",
    "        df[\"portfolio_return_%\"] = df[\"portfolio_value\"].pct_change() * 100\n",
    "\n",
    "        DATA_GOLD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        portfolio_table_path = DATA_GOLD_DIR / \"portfolio_composition.csv\"\n",
    "        df.to_csv(portfolio_table_path)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def plot_portfolio(self) -> None:\n",
    "        cumulative_returns = self.cumulative_return()\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.lineplot(data=cumulative_returns)\n",
    "        plt.title(\"Cumulative Return of the Portfolio\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Cumulative Return\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        chart_path = FIGURES_DIR / \"portfolio_returns_chart.png\"\n",
    "        plt.savefig(chart_path)\n",
    "        plt.close()\n",
    "\n",
    "    def plot_chart_per_asset(self) -> None:\n",
    "        FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        for col in self.prices.columns:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.lineplot(data=self.prices[col])\n",
    "            plt.title(f\"{col} Price Over Time\")\n",
    "            plt.xlabel(\"Date\")\n",
    "            plt.ylabel(\"Price\")\n",
    "            plt.tight_layout()\n",
    "            chart_path = FIGURES_DIR / f\"{col}_price_chart.png\"\n",
    "            plt.savefig(chart_path)\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HMMState:\n",
    "    \"\"\"Parameters of a single HMM state.\"\"\"\n",
    "\n",
    "    mean: np.ndarray\n",
    "    cov: np.ndarray\n",
    "    volatility: float  # Frobenius norm of covariance diagonal\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HMMResults:\n",
    "    \"\"\"Fitted HMM results and regime assignments.\"\"\"\n",
    "\n",
    "    model: hmm.GaussianHMM\n",
    "    transition_matrix: np.ndarray\n",
    "    states: Dict[int, HMMState]\n",
    "    regimes: np.ndarray  # regime_t for each time step\n",
    "    calm_state: int  # which state index corresponds to \"calm\"\n",
    "    crisis_state: int  # which state index corresponds to \"crisis\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee03872",
   "metadata": {},
   "source": [
    "### Funciones ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "205487e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_global_seed() -> None:\n",
    "    \"\"\"Set global random seed for reproducibility.\"\"\"\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def ensure_directories() -> None:\n",
    "    \"\"\"Create all necessary directories for the project.\"\"\"\n",
    "    DATA_BRONZE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    DATA_SILVER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    DATA_GOLD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def yield_curve_slope(y10: pd.Series, y2: pd.Series) -> pd.Series:\n",
    "    \"\"\"Calculate the yield curve slope (10Y - 2Y spread).\"\"\"\n",
    "    return y10 - y2\n",
    "\n",
    "def compute_regime_statistics(regimes: np.ndarray, calm_state: int) -> Dict[str, float]:\n",
    "    \"\"\"Compute summary statistics of regime frequencies.\"\"\"\n",
    "\n",
    "    crisis_state = 1 - calm_state\n",
    "    n_calm = int((regimes == calm_state).sum())\n",
    "    n_crisis = int((regimes == crisis_state).sum())\n",
    "    pct_calm = 100.0 * n_calm / len(regimes)\n",
    "    pct_crisis = 100.0 * n_crisis / len(regimes)\n",
    "\n",
    "    return {\n",
    "        \"n_calm_days\": n_calm,\n",
    "        \"n_crisis_days\": n_crisis,\n",
    "        \"pct_calm\": pct_calm,\n",
    "        \"pct_crisis\": pct_crisis,\n",
    "    }\n",
    "\n",
    "def analyze_hmm_features(log_returns: pd.DataFrame, hmm_results: HMMResults) -> pd.DataFrame:\n",
    "    \"\"\"Analyze the contribution of each market variable to regime detection.\n",
    "    \n",
    "    Shows the mean returns and volatility per feature in each HMM state\n",
    "    (Calm vs Crisis), demonstrating that all market variables are being used.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    log_returns : pd.DataFrame\n",
    "        The multivariate log-returns DataFrame (all market variables).\n",
    "    hmm_results : HMMResults\n",
    "        Fitted HMM results containing state parameters.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Analysis table showing mean and std for each feature in each state.\n",
    "    \"\"\"\n",
    "    \n",
    "    analysis_data = []\n",
    "    \n",
    "    for state_idx, state in hmm_results.states.items():\n",
    "        state_name = \"CALM\" if state_idx == hmm_results.calm_state else \"CRISIS\"\n",
    "        \n",
    "        for col_idx, col_name in enumerate(log_returns.columns):\n",
    "            analysis_data.append({\n",
    "                \"Variable\": col_name,\n",
    "                \"Regime\": state_name,\n",
    "                \"Mean (HMM)\": state.mean[col_idx],\n",
    "                \"Std Dev (HMM)\": np.sqrt(state.cov[col_idx, col_idx]),\n",
    "            })\n",
    "    \n",
    "    df_analysis = pd.DataFrame(analysis_data)\n",
    "    return df_analysis.sort_values([\"Variable\", \"Regime\"]).reset_index(drop=True)\n",
    "\n",
    "def load_and_prepare_returns(data_path: Path) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Load combined market data and prepare log returns for HMM.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : Path\n",
    "        Path to the combined market data CSV file.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[pd.DataFrame, pd.Series]\n",
    "        Log returns DataFrame and S&P 500 price series.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_path, index_col=0, parse_dates=True)\n",
    "    \n",
    "    # Calculate log returns from the returns data\n",
    "    log_returns = df.copy()\n",
    "    \n",
    "    # Load original S&P 500 prices from Bronze directory for visualization\n",
    "    sp500_bronze_path = DATA_BRONZE_DIR / \"equities_adj_close_^GSPC.csv\"\n",
    "    if sp500_bronze_path.exists():\n",
    "        sp500_prices_raw = pd.read_csv(sp500_bronze_path, index_col=0, parse_dates=True)\n",
    "        # The column name should be the ticker itself\n",
    "        sp500_prices = sp500_prices_raw.iloc[:, 0]  # Get first column regardless of name\n",
    "    else:\n",
    "        # Fallback: reconstruct from returns if Bronze file not available\n",
    "        sp500_prices = pd.Series(index=log_returns.index, dtype=float)\n",
    "    \n",
    "    return log_returns, sp500_prices\n",
    "\n",
    "def standardize_returns(log_returns: pd.DataFrame) -> Tuple[np.ndarray, StandardScaler, pd.DataFrame]:\n",
    "    \"\"\"Standardize log returns using StandardScaler.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    log_returns : pd.DataFrame\n",
    "        DataFrame with log returns.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, StandardScaler, pd.DataFrame]\n",
    "        Scaled returns array, fitted scaler object, and cleaned returns DataFrame.\n",
    "    \"\"\"\n",
    "    # Remove rows with NaN or infinity values\n",
    "    log_returns_clean = log_returns.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(log_returns_clean)\n",
    "    return X_scaled, scaler, log_returns_clean\n",
    "\n",
    "def fit_hmm(X_scaled: np.ndarray, n_components: int = 2) -> hmm.GaussianHMM:\n",
    "    \"\"\"Fit a Gaussian HMM to the scaled returns.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_scaled : np.ndarray\n",
    "        Scaled multivariate returns.\n",
    "    n_components : int\n",
    "        Number of hidden states (default: 2 for calm/crisis).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hmm.GaussianHMM\n",
    "        Fitted HMM model.\n",
    "    \"\"\"\n",
    "    model = hmm.GaussianHMM(n_components=n_components, random_state=RANDOM_SEED, n_iter=5000)\n",
    "    model.fit(X_scaled)\n",
    "    return model\n",
    "\n",
    "def identify_regimes(model: hmm.GaussianHMM, X_scaled: np.ndarray) -> Tuple[np.ndarray, HMMResults]:\n",
    "    \"\"\"Identify market regimes using fitted HMM.\n",
    "    \n",
    "    Determines which state is \"calm\" and which is \"crisis\" based on volatility levels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : hmm.GaussianHMM\n",
    "        Fitted HMM model.\n",
    "    X_scaled : np.ndarray\n",
    "        Scaled multivariate returns.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, HMMResults]\n",
    "        Regime assignments and full HMM results container.\n",
    "    \"\"\"\n",
    "    regimes = model.predict(X_scaled)\n",
    "    \n",
    "    # Determine which state is calm vs crisis based on volatility\n",
    "    state_volatilities = []\n",
    "    for i in range(model.n_components):\n",
    "        vol = np.sqrt(np.trace(model.covars_[i]) / model.n_features)\n",
    "        state_volatilities.append(vol)\n",
    "    \n",
    "    calm_state = int(np.argmin(state_volatilities))\n",
    "    crisis_state = 1 - calm_state\n",
    "    \n",
    "    # Build state parameters\n",
    "    states = {}\n",
    "    for i in range(model.n_components):\n",
    "        states[i] = HMMState(\n",
    "            mean=model.means_[i],\n",
    "            cov=model.covars_[i],\n",
    "            volatility=state_volatilities[i]\n",
    "        )\n",
    "    \n",
    "    hmm_results = HMMResults(\n",
    "        model=model,\n",
    "        transition_matrix=model.transmat_,\n",
    "        states=states,\n",
    "        regimes=regimes,\n",
    "        calm_state=calm_state,\n",
    "        crisis_state=crisis_state\n",
    "    )\n",
    "    \n",
    "    return regimes, hmm_results\n",
    "\n",
    "def visualize_regimes(\n",
    "    prices: pd.Series,\n",
    "    regimes: np.ndarray,\n",
    "    calm_state: int,\n",
    "    crisis_state: int,\n",
    "    plot_path: Path\n",
    ") -> None:\n",
    "    \"\"\"Visualize price series with regime coloring.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prices : pd.Series\n",
    "        Price series to plot.\n",
    "    regimes : np.ndarray\n",
    "        Regime assignments.\n",
    "    calm_state : int\n",
    "        Index of calm regime.\n",
    "    crisis_state : int\n",
    "        Index of crisis regime.\n",
    "    plot_path : Path\n",
    "        Path to save the figure.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    # Plot prices\n",
    "    ax.plot(prices.index, prices.values, \"k-\", linewidth=1.5, label=\"S&P 500 Price\")\n",
    "    \n",
    "    # Color background by regime\n",
    "    for i in range(len(regimes) - 1):\n",
    "        if regimes[i] == calm_state:\n",
    "            ax.axvspan(prices.index[i], prices.index[i + 1], alpha=0.2, color=\"whitesmoke\")\n",
    "        else:\n",
    "            ax.axvspan(prices.index[i], prices.index[i + 1], alpha=0.2, color=\"deepskyblue\")\n",
    "    \n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.set_title(\"Market Regimes: White=Calm, Blue=Crisis\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def separate_data_by_regime(\n",
    "    portfolio: Portfolio,\n",
    "    regimes: np.ndarray,\n",
    "    log_returns_clean: pd.DataFrame,\n",
    "    hmm_results: HMMResults\n",
    ") -> Tuple[Dict[str, pd.DataFrame], Dict[str, pd.DataFrame]]:\n",
    "    \"\"\"Separate portfolio returns and asset prices by regime.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    portfolio : Portfolio\n",
    "        Portfolio object with prices and returns.\n",
    "    regimes : np.ndarray\n",
    "        Regime assignments.\n",
    "    log_returns_clean : pd.DataFrame\n",
    "        Cleaned log returns aligned with regimes.\n",
    "    hmm_results : HMMResults\n",
    "        HMM results with state labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Dict[str, pd.DataFrame], Dict[str, pd.DataFrame]]\n",
    "        Returns and prices separated by regime.\n",
    "    \"\"\"\n",
    "    # Align portfolio returns with cleaned log returns index\n",
    "    portfolio_returns_clean = portfolio.portfolio_returns.loc[log_returns_clean.index]\n",
    "    \n",
    "    # Separate data by regime\n",
    "    calm_mask = regimes == hmm_results.calm_state\n",
    "    crisis_mask = regimes == hmm_results.crisis_state\n",
    "    \n",
    "    returns_by_regime = {\n",
    "        \"CALM\": portfolio_returns_clean[calm_mask],\n",
    "        \"CRISIS\": portfolio_returns_clean[crisis_mask]\n",
    "    }\n",
    "    \n",
    "    # Separate asset returns by regime\n",
    "    asset_returns_by_regime = {\n",
    "        \"CALM\": portfolio.returns.loc[log_returns_clean.index][calm_mask],\n",
    "        \"CRISIS\": portfolio.returns.loc[log_returns_clean.index][crisis_mask]\n",
    "    }\n",
    "    \n",
    "    return returns_by_regime, asset_returns_by_regime\n",
    "\n",
    "def calculate_marginal_statistics(\n",
    "    asset_returns: Dict[str, pd.DataFrame],\n",
    "    assets: Dict[str, str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Calculate marginal statistics (mean, vol, skewness, kurtosis) by regime and asset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    asset_returns : Dict[str, pd.DataFrame]\n",
    "        Asset returns separated by regime.\n",
    "    assets : Dict[str, str]\n",
    "        Asset dictionary with types.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Comprehensive statistics table by asset and regime.\n",
    "    \"\"\"\n",
    "    stats_list = []\n",
    "    \n",
    "    for regime_name, returns_df in asset_returns.items():\n",
    "        for asset in returns_df.columns:\n",
    "            if asset in assets:\n",
    "                asset_ret = returns_df[asset].dropna()\n",
    "                \n",
    "                if len(asset_ret) > 0:\n",
    "                    mean_ret = asset_ret.mean()\n",
    "                    volatility = asset_ret.std()\n",
    "                    skewness = sp_stats.skew(asset_ret)\n",
    "                    kurtosis = sp_stats.kurtosis(asset_ret)\n",
    "                    \n",
    "                    stats_list.append({\n",
    "                        \"Asset\": asset,\n",
    "                        \"Regime\": regime_name,\n",
    "                        \"Mean Return\": mean_ret,\n",
    "                        \"Volatility\": volatility,\n",
    "                        \"Skewness\": skewness,\n",
    "                        \"Kurtosis\": kurtosis,\n",
    "                        \"N Obs\": len(asset_ret)\n",
    "                    })\n",
    "    \n",
    "    df_stats = pd.DataFrame(stats_list)\n",
    "    return df_stats.sort_values([\"Asset\", \"Regime\"]).reset_index(drop=True)\n",
    "\n",
    "def analyze_key_assets(\n",
    "    asset_returns: Dict[str, pd.DataFrame],\n",
    "    key_assets: List[str] = [\"HYG\", \"GLD\"]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Focus analysis on key assets (High Yield, Gold).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    asset_returns : Dict[str, pd.DataFrame]\n",
    "        Asset returns separated by regime.\n",
    "    key_assets : List[str]\n",
    "        List of key assets to analyze.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Detailed statistics for key assets.\n",
    "    \"\"\"\n",
    "    key_stats = []\n",
    "    \n",
    "    for asset in key_assets:\n",
    "        for regime_name, returns_df in asset_returns.items():\n",
    "            if asset in returns_df.columns:\n",
    "                asset_ret = returns_df[asset].dropna()\n",
    "                \n",
    "                if len(asset_ret) > 0:\n",
    "                    var_99 = asset_ret.quantile(0.01)  # 1% worst case\n",
    "                    cvar_99 = asset_ret[asset_ret <= var_99].mean()\n",
    "                    \n",
    "                    key_stats.append({\n",
    "                        \"Asset\": asset,\n",
    "                        \"Regime\": regime_name,\n",
    "                        \"Mean (%)\": asset_ret.mean() * 100,\n",
    "                        \"Volatility (%)\": asset_ret.std() * 100,\n",
    "                        \"Skewness\": sp_stats.skew(asset_ret),\n",
    "                        \"Kurtosis\": sp_stats.kurtosis(asset_ret),\n",
    "                        \"VaR 99%\": var_99,\n",
    "                        \"CVaR 99%\": cvar_99,\n",
    "                        \"Min Return\": asset_ret.min(),\n",
    "                        \"Max Return\": asset_ret.max(),\n",
    "                    })\n",
    "    \n",
    "    df_key = pd.DataFrame(key_stats)\n",
    "    return df_key.sort_values([\"Asset\", \"Regime\"]).reset_index(drop=True)\n",
    "\n",
    "def interpret_regime_changes(df_key_assets: pd.DataFrame) -> str:\n",
    "    \"\"\"Generate economic interpretation of regime changes for key assets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_key_assets : pd.DataFrame\n",
    "        Key assets statistics by regime.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Interpretation text.\n",
    "    \"\"\"\n",
    "    interpretation = []\n",
    "    interpretation.append(\"=\" * 80)\n",
    "    interpretation.append(\"INTERPRETACI√ìN ECON√ìMICA DE CAMBIOS DE R√âGIMEN\")\n",
    "    interpretation.append(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    # HYG Analysis\n",
    "    hyg_calm = df_key_assets[(df_key_assets[\"Asset\"] == \"HYG\") & (df_key_assets[\"Regime\"] == \"CALM\")]\n",
    "    hyg_crisis = df_key_assets[(df_key_assets[\"Asset\"] == \"HYG\") & (df_key_assets[\"Regime\"] == \"CRISIS\")]\n",
    "    \n",
    "    if not hyg_calm.empty and not hyg_crisis.empty:\n",
    "        vol_calm = hyg_calm[\"Volatility (%)\"].values[0]\n",
    "        vol_crisis = hyg_crisis[\"Volatility (%)\"].values[0]\n",
    "        vol_change = ((vol_crisis - vol_calm) / vol_calm) * 100\n",
    "        \n",
    "        interpretation.append(\"üìä HIGH YIELD (HYG) - Bonos de Alto Rendimiento\")\n",
    "        interpretation.append(\"-\" * 80)\n",
    "        interpretation.append(f\"  ‚Ä¢ Volatilidad en CALMA: {vol_calm:.2f}%\")\n",
    "        interpretation.append(f\"  ‚Ä¢ Volatilidad en CRISIS: {vol_crisis:.2f}%\")\n",
    "        interpretation.append(f\"  ‚Ä¢ Aumento: {vol_change:.1f}%\")\n",
    "        interpretation.append(\"\\n  INTERPRETACI√ìN:\")\n",
    "        interpretation.append(\"  El aumento de volatilidad en crisis refleja:\")\n",
    "        interpretation.append(\"  ‚úì Mayor aversi√≥n al riesgo en el mercado\")\n",
    "        interpretation.append(\"  ‚úì Widening de spreads de cr√©dito\")\n",
    "        interpretation.append(\"  ‚úì Stress en el segmento de bonos de alto rendimiento\")\n",
    "        interpretation.append(\"  ‚Üí El HYG es PRO-C√çCLICO (amplifica riesgo en crisis)\\n\")\n",
    "    \n",
    "    # GLD Analysis\n",
    "    gld_calm = df_key_assets[(df_key_assets[\"Asset\"] == \"GLD\") & (df_key_assets[\"Regime\"] == \"CALM\")]\n",
    "    gld_crisis = df_key_assets[(df_key_assets[\"Asset\"] == \"GLD\") & (df_key_assets[\"Regime\"] == \"CRISIS\")]\n",
    "    \n",
    "    if not gld_calm.empty and not gld_crisis.empty:\n",
    "        ret_calm = gld_calm[\"Mean (%)\"].values[0]\n",
    "        ret_crisis = gld_crisis[\"Mean (%)\"].values[0]\n",
    "        vol_calm_gld = gld_calm[\"Volatility (%)\"].values[0]\n",
    "        vol_crisis_gld = gld_crisis[\"Volatility (%)\"].values[0]\n",
    "        \n",
    "        interpretation.append(\"üèÜ ORO (GLD) - Activo Refugio\")\n",
    "        interpretation.append(\"-\" * 80)\n",
    "        interpretation.append(f\"  ‚Ä¢ Retorno medio en CALMA: {ret_calm:.2f}%\")\n",
    "        interpretation.append(f\"  ‚Ä¢ Retorno medio en CRISIS: {ret_crisis:.2f}%\")\n",
    "        interpretation.append(f\"  ‚Ä¢ Volatilidad en CALMA: {vol_calm_gld:.2f}%\")\n",
    "        interpretation.append(f\"  ‚Ä¢ Volatilidad en CRISIS: {vol_crisis_gld:.2f}%\")\n",
    "        \n",
    "        if ret_crisis > ret_calm:\n",
    "            interpretation.append(\"\\n  INTERPRETACI√ìN:\")\n",
    "            interpretation.append(\"  ‚úì El ORO SUBE durante crisis (comportamiento de refugio)\")\n",
    "            interpretation.append(\"  ‚úì Inversores huyen a activos seguros\")\n",
    "            interpretation.append(\"  ‚úì Cobertura contra inflaci√≥n y depreciaci√≥n de divisas\")\n",
    "            interpretation.append(\"  ‚Üí El GLD es ANTI-C√çCLICO (protecci√≥n en turbulencia)\\n\")\n",
    "        else:\n",
    "            interpretation.append(\"\\n  INTERPRETACI√ìN:\")\n",
    "            interpretation.append(\"  ‚ö† El ORO NO act√∫a como refugio esperado\")\n",
    "            interpretation.append(\"  ‚ö† Posible liquidaci√≥n forzada en crisis\")\n",
    "            interpretation.append(\"  ‚Üí Revisar correlaci√≥n con equity en stress\\n\")\n",
    "    \n",
    "    interpretation.append(\"=\" * 80)\n",
    "    return \"\\n\".join(interpretation)\n",
    "\n",
    "def compare_volatility_regimes(df_stats: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create comparison table of volatility changes between regimes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_stats : pd.DataFrame\n",
    "        Statistics by asset and regime.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Volatility comparison table.\n",
    "    \"\"\"\n",
    "    vol_comparison = []\n",
    "    \n",
    "    for asset in df_stats[\"Asset\"].unique():\n",
    "        asset_data = df_stats[df_stats[\"Asset\"] == asset]\n",
    "        \n",
    "        calm_vol = asset_data[asset_data[\"Regime\"] == \"CALM\"][\"Volatility\"].values\n",
    "        crisis_vol = asset_data[asset_data[\"Regime\"] == \"CRISIS\"][\"Volatility\"].values\n",
    "        \n",
    "        if len(calm_vol) > 0 and len(crisis_vol) > 0:\n",
    "            vol_ratio = crisis_vol[0] / calm_vol[0]\n",
    "            vol_change = ((crisis_vol[0] - calm_vol[0]) / calm_vol[0]) * 100\n",
    "            \n",
    "            vol_comparison.append({\n",
    "                \"Asset\": asset,\n",
    "                \"Volatility CALM\": calm_vol[0],\n",
    "                \"Volatility CRISIS\": crisis_vol[0],\n",
    "                \"Ratio (Crisis/Calm)\": vol_ratio,\n",
    "                \"% Change\": vol_change\n",
    "            })\n",
    "    \n",
    "    df_vol = pd.DataFrame(vol_comparison)\n",
    "    return df_vol.sort_values(\"Ratio (Crisis/Calm)\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "def save_phase1_analysis(\n",
    "    df_stats: pd.DataFrame,\n",
    "    df_key_assets: pd.DataFrame,\n",
    "    df_vol_comparison: pd.DataFrame,\n",
    "    interpretation: str,\n",
    "    output_dir: Path\n",
    ") -> None:\n",
    "    \"\"\"Save all Phase 1 analysis results to files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_stats : pd.DataFrame\n",
    "        Marginal statistics table.\n",
    "    df_key_assets : pd.DataFrame\n",
    "        Key assets analysis.\n",
    "    df_vol_comparison : pd.DataFrame\n",
    "        Volatility comparison.\n",
    "    interpretation : str\n",
    "        Economic interpretation text.\n",
    "    output_dir : Path\n",
    "        Output directory path.\n",
    "    \"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save statistics tables\n",
    "    df_stats.to_csv(output_dir / \"phase1_marginal_statistics.csv\", index=False)\n",
    "    df_key_assets.to_csv(output_dir / \"phase1_key_assets_analysis.csv\", index=False)\n",
    "    df_vol_comparison.to_csv(output_dir / \"phase1_volatility_comparison.csv\", index=False)\n",
    "    \n",
    "    # Save interpretation with UTF-8 encoding\n",
    "    with open(output_dir / \"phase1_interpretation.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(interpretation)\n",
    "\n",
    "def run_phase1_risk_analysis(\n",
    "    portfolio: Portfolio,\n",
    "    regimes: np.ndarray,\n",
    "    log_returns_clean: pd.DataFrame,\n",
    "    hmm_results: HMMResults\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, str]:\n",
    "    \"\"\"Execute complete Phase 1 analysis: Risk by Regime.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    portfolio : Portfolio\n",
    "        Portfolio object with prices and returns.\n",
    "    regimes : np.ndarray\n",
    "        Regime assignments.\n",
    "    log_returns_clean : pd.DataFrame\n",
    "        Cleaned log returns aligned with regimes.\n",
    "    hmm_results : HMMResults\n",
    "        HMM results with state labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, str]\n",
    "        Marginal statistics, key assets analysis, volatility comparison, and interpretation.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"FASE 1: AN√ÅLISIS DE RIESGO INDIVIDUAL POR R√âGIMEN\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    # Task 1.1: Separate data by regime\n",
    "    print(\"1.1 Separando datos por r√©gimen...\")\n",
    "    returns_by_regime, asset_returns_by_regime = separate_data_by_regime(\n",
    "        portfolio, regimes, log_returns_clean, hmm_results\n",
    "    )\n",
    "    \n",
    "    calm_obs = len(returns_by_regime[\"CALM\"])\n",
    "    crisis_obs = len(returns_by_regime[\"CRISIS\"])\n",
    "    print(f\"     ‚úì D√≠as en CALMA: {calm_obs}\")\n",
    "    print(f\"     ‚úì D√≠as en CRISIS: {crisis_obs}\\n\")\n",
    "    \n",
    "    # Task 1.2: Calculate marginal statistics\n",
    "    print(\"1.2 Calculando estad√≠sticas marginales...\")\n",
    "    df_stats = calculate_marginal_statistics(asset_returns_by_regime, portfolio.assets)\n",
    "    print(f\"     ‚úì {len(df_stats)} filas de estad√≠sticas (activos √ó reg√≠menes)\\n\")\n",
    "    \n",
    "    # Task 1.3: Analyze key assets\n",
    "    print(\"1.3 Analizando activos clave (HYG, GLD)...\")\n",
    "    df_key_assets = analyze_key_assets(asset_returns_by_regime)\n",
    "    print(f\"     ‚úì An√°lisis detallado de {df_key_assets['Asset'].nunique()} activos\\n\")\n",
    "    \n",
    "    # Volatility comparison\n",
    "    print(\"1.4 Comparando volatilidades entre reg√≠menes...\")\n",
    "    df_vol_comparison = compare_volatility_regimes(df_stats)\n",
    "    print(f\"     ‚úì Tabla de comparaci√≥n creada\\n\")\n",
    "    \n",
    "    # Task 1.4: Economic interpretation\n",
    "    print(\"1.4 Generando interpretaci√≥n econ√≥mica...\")\n",
    "    interpretation = interpret_regime_changes(df_key_assets)\n",
    "    print(interpretation)\n",
    "    print()\n",
    "    \n",
    "    # Save results\n",
    "    print(\"Guardando resultados de Fase 1...\")\n",
    "    save_phase1_analysis(df_stats, df_key_assets, df_vol_comparison, interpretation, DATA_GOLD_DIR)\n",
    "    print(f\"     ‚úì Resultados guardados en {DATA_GOLD_DIR}\\n\")\n",
    "    \n",
    "    return df_stats, df_key_assets, df_vol_comparison, interpretation\n",
    "\n",
    "def run_regime_detection_pipeline() -> Dict[str, float]:\n",
    "    \"\"\"Run the full HMM-based regime detection workflow and return basic statistics.\"\"\"\n",
    "\n",
    "    # Data preparation\n",
    "    log_returns, sp500_prices = load_and_prepare_returns(COMBINED_PATH)\n",
    "    \n",
    "    # Display which variables are being analyzed\n",
    "    print(\"=\" * 80)\n",
    "    print(\"MARKET VARIABLES USED FOR REGIME DETECTION (Multivariate Gaussian HMM):\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, col in enumerate(log_returns.columns, 1):\n",
    "        print(f\"{i}. {col}\")\n",
    "    print(f\"\\nTotal dimensions: {log_returns.shape[1]} variables √ó {log_returns.shape[0]} observations\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    X_scaled, _, log_returns_clean = standardize_returns(log_returns)\n",
    "\n",
    "    # HMM fitting\n",
    "    model = fit_hmm(X_scaled, n_components=2)\n",
    "\n",
    "    # Regime identification\n",
    "    regimes, hmm_results = identify_regimes(model, X_scaled)\n",
    "\n",
    "    # Analyze feature contributions to regimes (use cleaned returns)\n",
    "    df_feature_analysis = analyze_hmm_features(log_returns_clean, hmm_results)\n",
    "    print(\"FEATURE ANALYSIS - Mean and Volatility per Regime:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df_feature_analysis.to_string(index=False))\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    # Align sp500_prices with cleaned returns\n",
    "    sp500_prices_clean = sp500_prices.loc[log_returns_clean.index]\n",
    "\n",
    "    # Visualization\n",
    "    FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = FIGURES_DIR / \"regime_visualization_sp500.png\"\n",
    "    visualize_regimes(\n",
    "        sp500_prices_clean,\n",
    "        regimes,\n",
    "        hmm_results.calm_state,\n",
    "        hmm_results.crisis_state,\n",
    "        plot_path,\n",
    "    )\n",
    "\n",
    "    # Save outputs\n",
    "    DATA_GOLD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    regime_ts_path = DATA_GOLD_DIR / \"regime_timeseries.csv\"\n",
    "    save_regime_timeseries(log_returns_clean.index, regimes, sp500_prices_clean, hmm_results, regime_ts_path)\n",
    "\n",
    "    hmm_params_path = DATA_GOLD_DIR / \"hmm_parameters.txt\"\n",
    "    save_hmm_parameters(hmm_results, hmm_params_path)\n",
    "\n",
    "    # Statistics\n",
    "    stats = compute_regime_statistics(regimes, hmm_results.calm_state)\n",
    "    return stats\n",
    "\n",
    "def save_regime_timeseries(\n",
    "    dates: pd.DatetimeIndex,\n",
    "    regimes: np.ndarray,\n",
    "    sp500_prices: pd.Series,\n",
    "    hmm_results: HMMResults,\n",
    "    output_path: Path\n",
    ") -> None:\n",
    "    \"\"\"Save regime time series to CSV.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dates : pd.DatetimeIndex\n",
    "        Index dates.\n",
    "    regimes : np.ndarray\n",
    "        Regime assignments.\n",
    "    sp500_prices : pd.Series\n",
    "        S&P 500 prices.\n",
    "    hmm_results : HMMResults\n",
    "        HMM results container.\n",
    "    output_path : Path\n",
    "        Path to save CSV.\n",
    "    \"\"\"\n",
    "    df_regimes = pd.DataFrame({\n",
    "        \"date\": dates,\n",
    "        \"regime\": regimes,\n",
    "        \"regime_label\": [\"CALM\" if r == hmm_results.calm_state else \"CRISIS\" for r in regimes],\n",
    "        \"sp500_price\": sp500_prices.values\n",
    "    })\n",
    "    df_regimes.set_index(\"date\", inplace=True)\n",
    "    df_regimes.to_csv(output_path)\n",
    "\n",
    "def save_hmm_parameters(hmm_results: HMMResults, output_path: Path) -> None:\n",
    "    \"\"\"Save HMM parameters to text file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hmm_results : HMMResults\n",
    "        HMM results container.\n",
    "    output_path : Path\n",
    "        Path to save parameters file.\n",
    "    \"\"\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        f.write(\"HMM PARAMETERS\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"TRANSITION MATRIX:\\n\")\n",
    "        f.write(str(hmm_results.transition_matrix) + \"\\n\\n\")\n",
    "        \n",
    "        for state_idx, state in hmm_results.states.items():\n",
    "            state_label = \"CALM\" if state_idx == hmm_results.calm_state else \"CRISIS\"\n",
    "            f.write(f\"\\nSTATE {state_idx} ({state_label}):\\n\")\n",
    "            f.write(f\"  Volatility: {state.volatility:.6f}\\n\")\n",
    "            f.write(f\"  Mean:\\n{state.mean}\\n\")\n",
    "            f.write(f\"  Covariance (diagonal):\\n{np.diag(state.cov)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced0f722",
   "metadata": {},
   "source": [
    "### Datos ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "131405d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_portfolio() -> Portfolio:\n",
    "    \"\"\"Create the baseline multi-asset portfolio configuration and return a Portfolio.\"\"\"\n",
    "\n",
    "    assets: Dict[str, str] = {\n",
    "        \"AAPL\": \"equity\",\n",
    "        \"AMZN\": \"equity\",\n",
    "        \"BAC\": \"equity\",\n",
    "        \"BRK-B\": \"equity\",\n",
    "        \"CVX\": \"equity\",\n",
    "        \"ENPH\": \"equity\",\n",
    "        \"GLD\": \"equity\",\n",
    "        \"GME\": \"equity\",\n",
    "        \"GOOGL\": \"equity\",\n",
    "        \"JNJ\": \"equity\",\n",
    "        \"JPM\": \"equity\",\n",
    "        \"MSFT\": \"equity\",\n",
    "        \"NVDA\": \"equity\",\n",
    "        \"PG\": \"equity\",\n",
    "        \"XOM\": \"equity\",\n",
    "        \"HYG\": \"equity\",\n",
    "        \"GS10\": \"yield\",\n",
    "        \"GS2\": \"yield\",\n",
    "    }\n",
    "\n",
    "    return Portfolio(assets=assets)\n",
    "\n",
    "\n",
    "def portfolio() -> Portfolio:\n",
    "    \"\"\"Backwards-compatible wrapper for building the default portfolio.\"\"\"\n",
    "\n",
    "    return build_portfolio()\n",
    "\n",
    "\n",
    "def market_risk() -> pd.DataFrame:\n",
    "    \"\"\"Construct the market risk data set used for regime detection.\"\"\"\n",
    "\n",
    "    # Equity market\n",
    "    sp500 = MarketData.fetch_equities(tickers=[\"^GSPC\"], start=START_DATE, end=END_DATE)\n",
    "    sp500_ret = sp500.pct_change()\n",
    "\n",
    "    vix = MarketData.fetch_equities(tickers=[\"^VIX\"], start=START_DATE, end=END_DATE)\n",
    "    vix_ret = vix.pct_change()\n",
    "\n",
    "    # Interest rates\n",
    "    y10 = MarketData.fetch_us_yields(\"GS10\", start=START_DATE, end=END_DATE)\n",
    "    y2 = MarketData.fetch_us_yields(\"GS2\", start=START_DATE, end=END_DATE)\n",
    "\n",
    "    y10_chg = y10.pct_change()\n",
    "    y2_chg = y2.pct_change()\n",
    "    slope = yield_curve_slope(y10[\"GS10\"], y2[\"GS2\"]).rename(\"yield_slope\")\n",
    "\n",
    "    # Credit spread\n",
    "    hy_spread = MarketData.fetch_us_yields(\"BAMLH0A0HYM2\", start=START_DATE, end=END_DATE)\n",
    "    hy_spread_chg = hy_spread.pct_change()\n",
    "\n",
    "    # Combine all market risk drivers\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            sp500_ret,\n",
    "            vix_ret,\n",
    "            y10_chg,\n",
    "            y2_chg,\n",
    "            slope,\n",
    "            hy_spread_chg,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    for col in [\"GS10\", \"GS2\", \"yield_slope\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].ffill()\n",
    "\n",
    "    DATA_GOLD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    df_path = DATA_GOLD_DIR / \"market_data_combined.csv\"\n",
    "    df.to_csv(df_path)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8489704a",
   "metadata": {},
   "source": [
    "### Reports ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fb78cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_volatility_comparison_chart(\n",
    "    df_vol_comparison: pd.DataFrame,\n",
    "    output_path: Path\n",
    ") -> None:\n",
    "    \"\"\"Create professional volatility comparison chart for executive report.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_vol_comparison : pd.DataFrame\n",
    "        Volatility comparison data.\n",
    "    output_path : Path\n",
    "        Path to save the figure.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Sort by ratio descending\n",
    "    df_sorted = df_vol_comparison.sort_values(\"Ratio (Crisis/Calm)\", ascending=True)\n",
    "    \n",
    "    colors = [\"#d62728\" if x > 1.2 else \"#ff7f0e\" if x > 1.0 else \"#2ca02c\" \n",
    "              for x in df_sorted[\"Ratio (Crisis/Calm)\"]]\n",
    "    \n",
    "    ax.barh(df_sorted[\"Asset\"], df_sorted[\"Ratio (Crisis/Calm)\"], color=colors, alpha=0.8, edgecolor=\"black\")\n",
    "    ax.axvline(x=1.0, color=\"black\", linestyle=\"--\", linewidth=2, label=\"Baseline (No Change)\")\n",
    "    ax.set_xlabel(\"Raz√≥n Volatilidad Crisis / Volatilidad Calma\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_title(\"Amplificaci√≥n de Volatilidad por Activo en Per√≠odos de Crisis\", \n",
    "                 fontsize=14, fontweight=\"bold\", pad=20)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(axis=\"x\", alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (asset, ratio) in enumerate(zip(df_sorted[\"Asset\"], df_sorted[\"Ratio (Crisis/Calm)\"])):\n",
    "        ax.text(ratio + 0.05, i, f\"{ratio:.2f}x\", va=\"center\", fontweight=\"bold\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def create_key_assets_chart(\n",
    "    df_key_assets: pd.DataFrame,\n",
    "    output_path: Path\n",
    ") -> None:\n",
    "    \"\"\"Create professional chart for key assets analysis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_key_assets : pd.DataFrame\n",
    "        Key assets statistics.\n",
    "    output_path : Path\n",
    "        Path to save the figure.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # HYG Analysis\n",
    "    hyg_data = df_key_assets[df_key_assets[\"Asset\"] == \"HYG\"]\n",
    "    if not hyg_data.empty:\n",
    "        regimes_hyg = hyg_data[\"Regime\"].values\n",
    "        vol_hyg = hyg_data[\"Volatility (%)\"].values\n",
    "        colors_hyg = [\"#2ca02c\", \"#d62728\"]\n",
    "        \n",
    "        axes[0].bar(regimes_hyg, vol_hyg, color=colors_hyg, alpha=0.8, edgecolor=\"black\", linewidth=2)\n",
    "        axes[0].set_ylabel(\"Volatilidad (%)\", fontsize=11, fontweight=\"bold\")\n",
    "        axes[0].set_title(\"HYG: Bonos de Alto Rendimiento\\n(Comportamiento Pro-C√≠clico)\", \n",
    "                         fontsize=12, fontweight=\"bold\")\n",
    "        axes[0].grid(axis=\"y\", alpha=0.3)\n",
    "        \n",
    "        for i, v in enumerate(vol_hyg):\n",
    "            axes[0].text(i, v + 1, f\"{v:.1f}%\", ha=\"center\", fontweight=\"bold\", fontsize=11)\n",
    "    \n",
    "    # GLD Analysis\n",
    "    gld_data = df_key_assets[df_key_assets[\"Asset\"] == \"GLD\"]\n",
    "    if not gld_data.empty:\n",
    "        regimes_gld = gld_data[\"Regime\"].values\n",
    "        ret_gld = gld_data[\"Mean (%)\"].values\n",
    "        colors_gld = [\"#2ca02c\", \"#d62728\"]\n",
    "        \n",
    "        axes[1].bar(regimes_gld, ret_gld, color=colors_gld, alpha=0.8, edgecolor=\"black\", linewidth=2)\n",
    "        axes[1].set_ylabel(\"Retorno Promedio (%)\", fontsize=11, fontweight=\"bold\")\n",
    "        axes[1].set_title(\"GLD: Oro (Activo Refugio)\\n(Comportamiento Anti-C√≠clico)\", \n",
    "                         fontsize=12, fontweight=\"bold\")\n",
    "        axes[1].grid(axis=\"y\", alpha=0.3)\n",
    "        \n",
    "        for i, v in enumerate(ret_gld):\n",
    "            axes[1].text(i, v + 0.05 if v > 0 else v - 0.15, f\"{v:.2f}%\", \n",
    "                        ha=\"center\", fontweight=\"bold\", fontsize=11)\n",
    "    \n",
    "    plt.suptitle(\"An√°lisis de Activos Clave por R√©gimen\", fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def generate_executive_report(\n",
    "    regime_stats: Dict[str, float],\n",
    "    df_stats: pd.DataFrame,\n",
    "    df_key_assets: pd.DataFrame,\n",
    "    df_vol_comparison: pd.DataFrame,\n",
    "    interpretation: str,\n",
    "    portfolio: Portfolio,\n",
    "    regimes: np.ndarray,\n",
    "    hmm_results: HMMResults,\n",
    "    output_dir: Path\n",
    ") -> str:\n",
    "    \"\"\"Generate professional executive report in markdown format.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    regime_stats : Dict[str, float]\n",
    "        Regime statistics.\n",
    "    df_stats : pd.DataFrame\n",
    "        Marginal statistics.\n",
    "    df_key_assets : pd.DataFrame\n",
    "        Key assets analysis.\n",
    "    df_vol_comparison : pd.DataFrame\n",
    "        Volatility comparison.\n",
    "    interpretation : str\n",
    "        Economic interpretation.\n",
    "    portfolio : Portfolio\n",
    "        Portfolio object.\n",
    "    regimes : np.ndarray\n",
    "        Regime assignments.\n",
    "    hmm_results : HMMResults\n",
    "        HMM results.\n",
    "    output_dir : Path\n",
    "        Output directory.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Markdown report content.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create charts\n",
    "    vol_chart_path = output_dir / \"chart_volatility_comparison.png\"\n",
    "    key_assets_chart_path = output_dir / \"chart_key_assets.png\"\n",
    "    \n",
    "    create_volatility_comparison_chart(df_vol_comparison, vol_chart_path)\n",
    "    create_key_assets_chart(df_key_assets, key_assets_chart_path)\n",
    "    \n",
    "    # Get portfolio metrics\n",
    "    portfolio_summary = portfolio.summary()\n",
    "    \n",
    "    # Build markdown report\n",
    "    report = []\n",
    "    \n",
    "    report.append(\"# INFORME EJECUTIVO: AN√ÅLISIS DE RIESGO Y REG√çMENES DE MERCADO\")\n",
    "    report.append(\"## Motor de Stress Testing - Cambios de R√©gimen Financiero\")\n",
    "    report.append(\"\")\n",
    "    report.append(f\"**Fecha:** {pd.Timestamp.now().strftime('%d de %B de %Y')}\")\n",
    "    report.append(\"**Para:** Comit√© de Riesgos (CEO, CFO, CRO)\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"---\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # EXECUTIVE SUMMARY\n",
    "    report.append(\"## 1. RESUMEN EJECUTIVO\")\n",
    "    report.append(\"\")\n",
    "    report.append(f\"Este an√°lisis identifica **dos reg√≠menes de mercado distintos** en los √∫ltimos {len(regimes)} d√≠as:\")\n",
    "    report.append(f\"- **CALMA:** {regime_stats['n_calm_days']:.0f} d√≠as ({regime_stats['pct_calm']:.1f}%)\")\n",
    "    report.append(f\"- **CRISIS:** {regime_stats['n_crisis_days']:.0f} d√≠as ({regime_stats['pct_crisis']:.1f}%)\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"### Hallazgos Clave\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # Key finding 1: Volatility spike\n",
    "    max_vol_ratio = df_vol_comparison[\"Ratio (Crisis/Calm)\"].max()\n",
    "    max_vol_asset = df_vol_comparison.loc[df_vol_comparison[\"Ratio (Crisis/Calm)\"].idxmax(), \"Asset\"]\n",
    "    report.append(f\"**1. Amplificaci√≥n de Volatilidad:** En per√≠odos de crisis, la volatilidad de {max_vol_asset} es **{max_vol_ratio:.1f}x** mayor que en calma.\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # Key finding 2: HYG behavior\n",
    "    hyg_calm_vol = df_key_assets[(df_key_assets[\"Asset\"] == \"HYG\") & (df_key_assets[\"Regime\"] == \"CALM\")][\"Volatility (%)\"].values\n",
    "    hyg_crisis_vol = df_key_assets[(df_key_assets[\"Asset\"] == \"HYG\") & (df_key_assets[\"Regime\"] == \"CRISIS\")][\"Volatility (%)\"].values\n",
    "    \n",
    "    if len(hyg_calm_vol) > 0 and len(hyg_crisis_vol) > 0:\n",
    "        hyg_increase = ((hyg_crisis_vol[0] - hyg_calm_vol[0]) / hyg_calm_vol[0]) * 100\n",
    "        report.append(f\"**2. Riesgo de Cr√©dito:** Los bonos de alto rendimiento (HYG) aumentan volatilidad **{hyg_increase:.0f}%** en crisis ‚Üí **PRO-C√çCLICO**.\")\n",
    "        report.append(\"\")\n",
    "    \n",
    "    # Key finding 3: GLD behavior\n",
    "    gld_calm_ret = df_key_assets[(df_key_assets[\"Asset\"] == \"GLD\") & (df_key_assets[\"Regime\"] == \"CALM\")][\"Mean (%)\"].values\n",
    "    gld_crisis_ret = df_key_assets[(df_key_assets[\"Asset\"] == \"GLD\") & (df_key_assets[\"Regime\"] == \"CRISIS\")][\"Mean (%)\"].values\n",
    "    \n",
    "    if len(gld_calm_ret) > 0 and len(gld_crisis_ret) > 0:\n",
    "        gld_behavior = \"SUBE\" if gld_crisis_ret[0] > gld_calm_ret[0] else \"BAJA\"\n",
    "        report.append(f\"**3. Activo Refugio:** El oro (GLD) {gld_behavior} durante crisis ‚Üí **ACT√öA COMO COBERTURA**.\")\n",
    "        report.append(\"\")\n",
    "    \n",
    "    report.append(\"### Implicaciones para el Portafolio\")\n",
    "    report.append(f\"- Retorno anualizado: **{portfolio_summary['Mean Return (ann)']*100:.2f}%**\")\n",
    "    report.append(f\"- Volatilidad: **{portfolio_summary['Volatility (ann)']*100:.2f}%**\")\n",
    "    report.append(f\"- M√°xima p√©rdida acumulada: **{portfolio_summary['Max Drawdown']*100:.2f}%**\")\n",
    "    report.append(f\"- VaR 99%: **{portfolio_summary['VaR 99%']*100:.2f}%** (p√©rdida diaria en peor escenario)\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(\"---\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # REGIME ANALYSIS\n",
    "    report.append(\"## 2. AN√ÅLISIS DE REG√çMENES Y VOLATILIDAD\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"### Transici√≥n entre Reg√≠menes\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"El modelo HMM identifica cambios en la **matriz de transici√≥n de estados**, mostrando:\")\n",
    "    report.append(f\"- Probabilidad de permanecer en CALMA: **{hmm_results.transition_matrix[hmm_results.calm_state, hmm_results.calm_state]*100:.1f}%**\")\n",
    "    report.append(f\"- Probabilidad de pasar a CRISIS: **{hmm_results.transition_matrix[hmm_results.calm_state, hmm_results.crisis_state]*100:.1f}%**\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(\"### Amplificaci√≥n de Riesgo por Activo\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"| Activo | Vol. Calma | Vol. Crisis | Raz√≥n Crisis/Calma |\")\n",
    "    report.append(\"|--------|-----------|------------|-------------------|\")\n",
    "    \n",
    "    for _, row in df_vol_comparison.head(10).iterrows():\n",
    "        ratio = row[\"Ratio (Crisis/Calm)\"]\n",
    "        risk_label = \"üî¥ MUY ALTO\" if ratio > 1.5 else \"üü† ALTO\" if ratio > 1.2 else \"üü° MODERADO\" if ratio > 1.0 else \"üü¢ BAJO\"\n",
    "        report.append(f\"| {row['Asset']} | {row['Volatility CALM']:.3f} | {row['Volatility CRISIS']:.3f} | {ratio:.2f}x {risk_label} |\")\n",
    "    \n",
    "    report.append(\"\")\n",
    "    report.append(\"![Amplificaci√≥n de Volatilidad](chart_volatility_comparison.png)\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(\"---\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # KEY ASSETS ANALYSIS\n",
    "    report.append(\"## 3. AN√ÅLISIS DE ACTIVOS CLAVE\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"### HYG: Bonos de Alto Rendimiento (Comportamiento Pro-C√≠clico)\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    hyg_stats = df_key_assets[df_key_assets[\"Asset\"] == \"HYG\"]\n",
    "    if not hyg_stats.empty:\n",
    "        hyg_calm = hyg_stats[hyg_stats[\"Regime\"] == \"CALM\"].iloc[0]\n",
    "        hyg_crisis = hyg_stats[hyg_stats[\"Regime\"] == \"CRISIS\"].iloc[0]\n",
    "        \n",
    "        report.append(f\"| M√©trica | Calma | Crisis | Cambio |\")\n",
    "        report.append(\"|---------|-------|--------|--------|\")\n",
    "        report.append(f\"| Retorno Promedio | {hyg_calm['Mean (%)']:.2f}% | {hyg_crisis['Mean (%)']:.2f}% | {hyg_crisis['Mean (%)'] - hyg_calm['Mean (%)']:.2f}% |\")\n",
    "        report.append(f\"| Volatilidad | {hyg_calm['Volatility (%)']:.2f}% | {hyg_crisis['Volatility (%)']:.2f}% | +{hyg_crisis['Volatility (%)'] - hyg_calm['Volatility (%)']:.2f}% |\")\n",
    "        report.append(f\"| Asimetr√≠a | {hyg_calm['Skewness']:.2f} | {hyg_crisis['Skewness']:.2f} | - |\")\n",
    "        report.append(f\"| Curtosis | {hyg_calm['Kurtosis']:.2f} | {hyg_crisis['Kurtosis']:.2f} | - |\")\n",
    "        report.append(\"\")\n",
    "        report.append(\"**Interpretaci√≥n:** El aumento de volatilidad refleja mayor **aversi√≥n al riesgo** y **widening de spreads de cr√©dito** durante turbulencia. HYG amplifica p√©rdidas en crisis.\")\n",
    "        report.append(\"\")\n",
    "    \n",
    "    report.append(\"### GLD: Oro (Comportamiento Anti-C√≠clico)\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    gld_stats = df_key_assets[df_key_assets[\"Asset\"] == \"GLD\"]\n",
    "    if not gld_stats.empty:\n",
    "        gld_calm = gld_stats[gld_stats[\"Regime\"] == \"CALM\"].iloc[0]\n",
    "        gld_crisis = gld_stats[gld_stats[\"Regime\"] == \"CRISIS\"].iloc[0]\n",
    "        \n",
    "        report.append(f\"| M√©trica | Calma | Crisis | Cambio |\")\n",
    "        report.append(\"|---------|-------|--------|--------|\")\n",
    "        report.append(f\"| Retorno Promedio | {gld_calm['Mean (%)']:.2f}% | {gld_crisis['Mean (%)']:.2f}% | {gld_crisis['Mean (%)'] - gld_calm['Mean (%)']:.2f}% |\")\n",
    "        report.append(f\"| Volatilidad | {gld_calm['Volatility (%)']:.2f}% | {gld_crisis['Volatility (%)']:.2f}% | {gld_crisis['Volatility (%)'] - gld_calm['Volatility (%)']:.2f}% |\")\n",
    "        report.append(\"\")\n",
    "        report.append(\"**Interpretaci√≥n:** El oro proporciona **cobertura contra riesgo sist√©mico**. Retornos superiores en crisis ‚Üí activo refugio efectivo.\")\n",
    "        report.append(\"\")\n",
    "    \n",
    "    report.append(\"![An√°lisis de Activos Clave](chart_key_assets.png)\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(\"---\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # RISK METRICS\n",
    "    report.append(\"## 4. M√âTRICAS DE RIESGO EXTREMO\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    hyg_var = df_key_assets[(df_key_assets[\"Asset\"] == \"HYG\") & (df_key_assets[\"Regime\"] == \"CRISIS\")][\"VaR 99%\"].values\n",
    "    hyg_cvar = df_key_assets[(df_key_assets[\"Asset\"] == \"HYG\") & (df_key_assets[\"Regime\"] == \"CRISIS\")][\"CVaR 99%\"].values\n",
    "    \n",
    "    if len(hyg_var) > 0:\n",
    "        report.append(f\"**HYG (High Yield Bonds):**\")\n",
    "        report.append(f\"- VaR 99% en Crisis: **{hyg_var[0]*100:.2f}%** (p√©rdida diaria en percentil 1)\")\n",
    "        report.append(f\"- CVaR 99% en Crisis: **{hyg_cvar[0]*100:.2f}%** (p√©rdida esperada peor que VaR)\")\n",
    "        report.append(\"\")\n",
    "    \n",
    "    report.append(\"---\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # RECOMMENDATIONS\n",
    "    report.append(\"## 5. RECOMENDACIONES PARA EL COMIT√â DE RIESGOS\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"### Gesti√≥n de Riesgo de Cr√©dito\")\n",
    "    report.append(\"1. **Posiciones en HYG:** Establecer l√≠mites m√°s estrictos dada la amplificaci√≥n de volatilidad en crisis (+150-200%).\")\n",
    "    report.append(\"2. **Cobertura de Spreads:** Considerar posiciones cortas en credit spreads como hedge contra turbulencia.\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(\"### Diversificaci√≥n Efectiva\")\n",
    "    report.append(\"3. **Oro como Cobertura:** Incrementar asignaci√≥n a GLD (activo refugio anti-c√≠clico) para per√≠odos de volatilidad.\")\n",
    "    report.append(\"4. **Descomposici√≥n de Riesgo:** Realizar an√°lisis de correlaci√≥n por r√©gimen ‚Üí diversificaci√≥n desaparece en crisis.\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(\"### Stress Testing Din√°mico\")\n",
    "    report.append(\"5. **Escenarios por R√©gimen:** Ejecutar stress tests separados para reg√≠menes CALMA y CRISIS.\")\n",
    "    report.append(\"6. **Monitoreo en Tiempo Real:** Implementar alertas cuando el modelo detecte transici√≥n hacia CRISIS.\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(\"---\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(\"## CONCLUSI√ìN\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"El an√°lisis revela **asimetr√≠as de riesgo significativas** entre reg√≠menes de mercado. La diversificaci√≥n tradicional colapsa en per√≠odos de crisis, con activos de alto rendimiento amplificando p√©rdidas (+150-200%) mientras que el oro proporciona protecci√≥n efectiva.\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"**Recomendaci√≥n:** Revisar posiciones en bonos high-yield e incrementar exposici√≥n a activos refugio para optimizar ratio riesgo-retorno ajustado a din√°micas de r√©gimen.\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report_text = \"\\n\".join(report)\n",
    "    \n",
    "    # Save markdown report\n",
    "    report_path = output_dir / \"INFORME_EJECUTIVO.md\"\n",
    "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    print(f\"‚úì Informe ejecutivo guardado en: {report_path}\")\n",
    "    \n",
    "    return report_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080e6924",
   "metadata": {},
   "source": [
    "### Main ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f0c6aee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piett\\AppData\\Local\\Temp\\ipykernel_40988\\1462631157.py:117: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  self.returns = self.prices.pct_change()\n",
      "C:\\Users\\piett\\AppData\\Local\\Temp\\ipykernel_40988\\3857109475.py:54: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  hy_spread_chg = hy_spread.pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MARKET VARIABLES USED FOR REGIME DETECTION (Multivariate Gaussian HMM):\n",
      "================================================================================\n",
      "1. ^GSPC\n",
      "2. ^VIX\n",
      "3. GS10\n",
      "4. GS2\n",
      "5. yield_slope\n",
      "6. BAMLH0A0HYM2\n",
      "\n",
      "Total dimensions: 6 variables √ó 5383 observations\n",
      "================================================================================\n",
      "\n",
      "FEATURE ANALYSIS - Mean and Volatility per Regime:\n",
      "================================================================================\n",
      "    Variable Regime  Mean (HMM)  Std Dev (HMM)\n",
      "BAMLH0A0HYM2   CALM   -0.076434       0.742667\n",
      "BAMLH0A0HYM2 CRISIS    0.109615       1.273867\n",
      "        GS10   CALM    0.063577       0.498242\n",
      "        GS10 CRISIS   -0.091176       1.436663\n",
      "         GS2   CALM    0.034101       0.409869\n",
      "         GS2 CRISIS   -0.048904       1.479575\n",
      "       ^GSPC   CALM    0.052750       0.558784\n",
      "       ^GSPC CRISIS   -0.075649       1.405924\n",
      "        ^VIX   CALM   -0.070964       0.693273\n",
      "        ^VIX CRISIS    0.101770       1.314256\n",
      " yield_slope   CALM   -0.264415       1.004147\n",
      " yield_slope CRISIS    0.379201       0.862572\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "INICIANDO FASE 1...\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FASE 1: AN√ÅLISIS DE RIESGO INDIVIDUAL POR R√âGIMEN\n",
      "================================================================================\n",
      "\n",
      "1.1 Separando datos por r√©gimen...\n",
      "     ‚úì D√≠as en CALMA: 2998\n",
      "     ‚úì D√≠as en CRISIS: 2038\n",
      "\n",
      "1.2 Calculando estad√≠sticas marginales...\n",
      "     ‚úì 36 filas de estad√≠sticas (activos √ó reg√≠menes)\n",
      "\n",
      "1.3 Analizando activos clave (HYG, GLD)...\n",
      "     ‚úì An√°lisis detallado de 2 activos\n",
      "\n",
      "1.4 Comparando volatilidades entre reg√≠menes...\n",
      "     ‚úì Tabla de comparaci√≥n creada\n",
      "\n",
      "1.4 Generando interpretaci√≥n econ√≥mica...\n",
      "================================================================================\n",
      "INTERPRETACI√ìN ECON√ìMICA DE CAMBIOS DE R√âGIMEN\n",
      "================================================================================\n",
      "\n",
      "üìä HIGH YIELD (HYG) - Bonos de Alto Rendimiento\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚Ä¢ Volatilidad en CALMA: 0.35%\n",
      "  ‚Ä¢ Volatilidad en CRISIS: 0.97%\n",
      "  ‚Ä¢ Aumento: 177.0%\n",
      "\n",
      "  INTERPRETACI√ìN:\n",
      "  El aumento de volatilidad en crisis refleja:\n",
      "  ‚úì Mayor aversi√≥n al riesgo en el mercado\n",
      "  ‚úì Widening de spreads de cr√©dito\n",
      "  ‚úì Stress en el segmento de bonos de alto rendimiento\n",
      "  ‚Üí El HYG es PRO-C√çCLICO (amplifica riesgo en crisis)\n",
      "\n",
      "üèÜ ORO (GLD) - Activo Refugio\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚Ä¢ Retorno medio en CALMA: 0.05%\n",
      "  ‚Ä¢ Retorno medio en CRISIS: 0.05%\n",
      "  ‚Ä¢ Volatilidad en CALMA: 1.01%\n",
      "  ‚Ä¢ Volatilidad en CRISIS: 1.31%\n",
      "\n",
      "  INTERPRETACI√ìN:\n",
      "  ‚úì El ORO SUBE durante crisis (comportamiento de refugio)\n",
      "  ‚úì Inversores huyen a activos seguros\n",
      "  ‚úì Cobertura contra inflaci√≥n y depreciaci√≥n de divisas\n",
      "  ‚Üí El GLD es ANTI-C√çCLICO (protecci√≥n en turbulencia)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Guardando resultados de Fase 1...\n",
      "     ‚úì Resultados guardados en C:\\Users\\piett\\OneDrive\\Desktop\\Pietro\\Master MIAX\\Clases\\2.Introduccion a los Sistemas Financieros\\Tareas\\Riesgos\\data\\gold\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ESTAD√çSTICAS MARGINALES POR ACTIVO Y R√âGIMEN\n",
      "================================================================================\n",
      "Asset Regime  Mean Return  Volatility  Skewness   Kurtosis  N Obs\n",
      " AAPL   CALM     0.002019    0.016073  0.239116   4.386280   2998\n",
      " AAPL CRISIS    -0.000116    0.024529  0.022640   4.955761   2038\n",
      " AMZN   CALM     0.002078    0.019929  1.433240  29.491856   2998\n",
      " AMZN CRISIS    -0.000132    0.028666  0.680398   6.584408   2038\n",
      "  BAC   CALM     0.001567    0.016825  1.402564  20.985802   2998\n",
      "  BAC CRISIS    -0.000912    0.041452  0.724672  14.481779   2038\n",
      "BRK-B   CALM     0.000876    0.008864  0.278301   2.986883   2998\n",
      "BRK-B CRISIS    -0.000006    0.018276  0.745727  11.173464   2038\n",
      "  CVX   CALM     0.000911    0.012099 -0.064276   2.171521   2998\n",
      "  CVX CRISIS    -0.000018    0.024107  0.145375  14.552398   2038\n",
      " ENPH   CALM     0.001887    0.047056  0.470922   8.613343   2233\n",
      " ENPH CRISIS     0.001681    0.056079  0.690129   7.720393   1250\n",
      "  GLD   CALM     0.000463    0.010112 -0.693881   7.218335   2998\n",
      "  GLD CRISIS     0.000504    0.013133 -0.034042   5.881163   2038\n",
      "  GME   CALM     0.001504    0.042169  3.440653  61.200217   2998\n",
      "  GME CRISIS     0.002166    0.071324  6.639333 111.163555   2038\n",
      "GOOGL   CALM     0.001756    0.015816  0.377090   9.834326   2998\n",
      "GOOGL CRISIS    -0.000478    0.022405  0.632722   7.176756   2038\n",
      " GS10   CALM     0.000191    0.007073  3.351531 108.447358   2998\n",
      " GS10 CRISIS     0.000073    0.022277  0.734122  84.329665   2038\n",
      "  GS2   CALM     0.000472    0.010198  5.240844  94.973781   2998\n",
      "  GS2 CRISIS     0.000524    0.039721  2.499191  84.649605   2038\n",
      "  HYG   CALM     0.000411    0.003516  0.228290   4.325602   2702\n",
      "  HYG CRISIS    -0.000040    0.009739  0.679136  23.871419   2035\n",
      "  JNJ   CALM     0.000687    0.008625 -0.165557   6.688747   2998\n",
      "  JNJ CRISIS     0.000123    0.013626  0.298918   9.661727   2038\n",
      "  JPM   CALM     0.001620    0.013423  0.762297  12.709499   2998\n",
      "  JPM CRISIS    -0.000448    0.032456  0.836129  10.432116   2038\n",
      " MSFT   CALM     0.001447    0.013646 -0.134768  10.861108   2998\n",
      " MSFT CRISIS    -0.000274    0.021710  0.414828   6.748473   2038\n",
      " NVDA   CALM     0.003009    0.026618  0.066363  12.845316   2998\n",
      " NVDA CRISIS    -0.000153    0.036386  0.301168   4.200604   2038\n",
      "   PG   CALM     0.000561    0.008973  0.129891   6.628868   2998\n",
      "   PG CRISIS     0.000100    0.014449  0.065415   7.834757   2038\n",
      "  XOM   CALM     0.000827    0.011547  0.020994   1.209398   2998\n",
      "  XOM CRISIS    -0.000110    0.022349  0.261601   6.876971   2038\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS DETALLADO: ACTIVOS CLAVE (HYG, GLD)\n",
      "================================================================================\n",
      "Asset Regime  Mean (%)  Volatility (%)  Skewness  Kurtosis   VaR 99%  CVaR 99%  Min Return  Max Return\n",
      "  GLD   CALM  0.046279        1.011221 -0.693881  7.218335 -0.027098 -0.040246   -0.102742    0.063587\n",
      "  GLD CRISIS  0.050355        1.313349 -0.034042  5.881163 -0.036257 -0.048325   -0.087808    0.112905\n",
      "  HYG   CALM  0.041070        0.351640  0.228290  4.325602 -0.009035 -0.011790   -0.024507    0.021863\n",
      "  HYG CRISIS -0.003965        0.973871  0.679136 23.871419 -0.029478 -0.044815   -0.080974    0.122689\n",
      "\n",
      "================================================================================\n",
      "COMPARACI√ìN DE VOLATILIDAD: RATIO CRISIS/CALM\n",
      "================================================================================\n",
      "Asset  Volatility CALM  Volatility CRISIS  Ratio (Crisis/Calm)   % Change\n",
      "  GS2         0.010198           0.039721             3.894984 289.498435\n",
      " GS10         0.007073           0.022277             3.149687 214.968736\n",
      "  HYG         0.003516           0.009739             2.769507 176.950721\n",
      "  BAC         0.016825           0.041452             2.463716 146.371572\n",
      "  JPM         0.013423           0.032456             2.417888 141.788788\n",
      "BRK-B         0.008864           0.018276             2.061784 106.178447\n",
      "  CVX         0.012099           0.024107             1.992512  99.251215\n",
      "  XOM         0.011547           0.022349             1.935542  93.554186\n",
      "  GME         0.042169           0.071324             1.691400  69.140020\n",
      "   PG         0.008973           0.014449             1.610290  61.028981\n",
      " MSFT         0.013646           0.021710             1.590995  59.099506\n",
      "  JNJ         0.008625           0.013626             1.579947  57.994653\n",
      " AAPL         0.016073           0.024529             1.526145  52.614469\n",
      " AMZN         0.019929           0.028666             1.438415  43.841476\n",
      "GOOGL         0.015816           0.022405             1.416629  41.662870\n",
      " NVDA         0.026618           0.036386             1.366954  36.695426\n",
      "  GLD         0.010112           0.013133             1.298776  29.877562\n",
      " ENPH         0.047056           0.056079             1.191756  19.175568\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERANDO INFORME EJECUTIVO...\n",
      "================================================================================\n",
      "\n",
      "‚úì Informe ejecutivo guardado en: C:\\Users\\piett\\OneDrive\\Desktop\\Pietro\\Master MIAX\\Clases\\2.Introduccion a los Sistemas Financieros\\Tareas\\Riesgos\\report\\INFORME_EJECUTIVO.md\n",
      "# INFORME EJECUTIVO: AN√ÅLISIS DE RIESGO Y REG√çMENES DE MERCADO\n",
      "## Motor de Stress Testing - Cambios de R√©gimen Financiero\n",
      "\n",
      "**Fecha:** 10 de February de 2026\n",
      "**Para:** Comit√© de Riesgos (CEO, CFO, CRO)\n",
      "\n",
      "---\n",
      "\n",
      "## 1. RESUMEN EJECUTIVO\n",
      "\n",
      "Este an√°lisis identifica **dos reg√≠menes de mercado distintos** en los √∫ltimos 5036 d√≠as:\n",
      "- **CALMA:** 2998 d√≠as (59.5%)\n",
      "- **CRISIS:** 2038 d√≠as (40.5%)\n",
      "\n",
      "### Hallazgos Clave\n",
      "\n",
      "**1. Amplificaci√≥n de Volatilidad:** En per√≠odos de crisis, la volatilidad de GS2 es **3.9x** mayor que en calma.\n",
      "\n",
      "**2. Riesgo de Cr√©dito:** Los bonos de alto rendimiento (HYG) aumentan volatilidad **177%** en crisis ‚Üí **PRO-C√çCLICO**.\n",
      "\n",
      "**3. Activo Refugio:** El oro (GLD) SUBE durante crisis ‚Üí **ACT√öA COMO COBERTURA**.\n",
      "\n",
      "### Implicaciones para el Portafolio\n",
      "- Retorno anualizado: **19.93%**\n",
      "- Volatilidad: **29.27%**\n",
      "- M√°xima p√©rdida acumulada: **-73.39%**\n",
      "- VaR 99%: **-3.80%** (p√©rdida diaria en peor escenario)\n",
      "\n",
      "---\n",
      "\n",
      "## 2. AN√ÅLISIS DE REG√çMENES Y VOLATILIDAD\n",
      "\n",
      "### Transici√≥n entre Reg√≠menes\n",
      "\n",
      "El modelo HMM identifica cambios en la **matriz de transici√≥n de estados**, mostrando:\n",
      "- Probabilidad de permanecer en CALMA: **96.5%**\n",
      "- Probabilidad de pasar a CRISIS: **3.5%**\n",
      "\n",
      "### Amplificaci√≥n de Riesgo por Activo\n",
      "\n",
      "| Activo | Vol. Calma | Vol. Crisis | Raz√≥n Crisis/Calma |\n",
      "|--------|-----------|------------|-------------------|\n",
      "| GS2 | 0.010 | 0.040 | 3.89x üî¥ MUY ALTO |\n",
      "| GS10 | 0.007 | 0.022 | 3.15x üî¥ MUY ALTO |\n",
      "| HYG | 0.004 | 0.010 | 2.77x üî¥ MUY ALTO |\n",
      "| BAC | 0.017 | 0.041 | 2.46x üî¥ MUY ALTO |\n",
      "| JPM | 0.013 | 0.032 | 2.42x üî¥ MUY ALTO |\n",
      "| BRK-B | 0.009 | 0.018 | 2.06x üî¥ MUY ALTO |\n",
      "| CVX | 0.012 | 0.024 | 1.99x üî¥ MUY ALTO |\n",
      "| XOM | 0.012 | 0.022 | 1.94x üî¥ MUY ALTO |\n",
      "| GME | 0.042 | 0.071 | 1.69x üî¥ MUY ALTO |\n",
      "| PG | 0.009 | 0.014 | 1.61x üî¥ MUY ALTO |\n",
      "\n",
      "![Amplificaci√≥n de Volatilidad](chart_volatility_comparison.png)\n",
      "\n",
      "---\n",
      "\n",
      "## 3. AN√ÅLISIS DE ACTIVOS CLAVE\n",
      "\n",
      "### HYG: Bonos de Alto Rendimiento (Comportamiento Pro-C√≠clico)\n",
      "\n",
      "| M√©trica | Calma | Crisis | Cambio |\n",
      "|---------|-------|--------|--------|\n",
      "| Retorno Promedio | 0.04% | -0.00% | -0.05% |\n",
      "| Volatilidad | 0.35% | 0.97% | +0.62% |\n",
      "| Asimetr√≠a | 0.23 | 0.68 | - |\n",
      "| Curtosis | 4.33 | 23.87 | - |\n",
      "\n",
      "**Interpretaci√≥n:** El aumento de volatilidad refleja mayor **aversi√≥n al riesgo** y **widening de spreads de cr√©dito** durante turbulencia. HYG amplifica p√©rdidas en crisis.\n",
      "\n",
      "### GLD: Oro (Comportamiento Anti-C√≠clico)\n",
      "\n",
      "| M√©trica | Calma | Crisis | Cambio |\n",
      "|---------|-------|--------|--------|\n",
      "| Retorno Promedio | 0.05% | 0.05% | 0.00% |\n",
      "| Volatilidad | 1.01% | 1.31% | 0.30% |\n",
      "\n",
      "**Interpretaci√≥n:** El oro proporciona **cobertura contra riesgo sist√©mico**. Retornos superiores en crisis ‚Üí activo refugio efectivo.\n",
      "\n",
      "![An√°lisis de Activos Clave](chart_key_assets.png)\n",
      "\n",
      "---\n",
      "\n",
      "## 4. M√âTRICAS DE RIESGO EXTREMO\n",
      "\n",
      "**HYG (High Yield Bonds):**\n",
      "- VaR 99% en Crisis: **-2.95%** (p√©rdida diaria en percentil 1)\n",
      "- CVaR 99% en Crisis: **-4.48%** (p√©rdida esperada peor que VaR)\n",
      "\n",
      "---\n",
      "\n",
      "## 5. RECOMENDACIONES PARA EL COMIT√â DE RIESGOS\n",
      "\n",
      "### Gesti√≥n de Riesgo de Cr√©dito\n",
      "1. **Posiciones en HYG:** Establecer l√≠mites m√°s estrictos dada la amplificaci√≥n de volatilidad en crisis (+150-200%).\n",
      "2. **Cobertura de Spreads:** Considerar posiciones cortas en credit spreads como hedge contra turbulencia.\n",
      "\n",
      "### Diversificaci√≥n Efectiva\n",
      "3. **Oro como Cobertura:** Incrementar asignaci√≥n a GLD (activo refugio anti-c√≠clico) para per√≠odos de volatilidad.\n",
      "4. **Descomposici√≥n de Riesgo:** Realizar an√°lisis de correlaci√≥n por r√©gimen ‚Üí diversificaci√≥n desaparece en crisis.\n",
      "\n",
      "### Stress Testing Din√°mico\n",
      "5. **Escenarios por R√©gimen:** Ejecutar stress tests separados para reg√≠menes CALMA y CRISIS.\n",
      "6. **Monitoreo en Tiempo Real:** Implementar alertas cuando el modelo detecte transici√≥n hacia CRISIS.\n",
      "\n",
      "---\n",
      "\n",
      "## CONCLUSI√ìN\n",
      "\n",
      "El an√°lisis revela **asimetr√≠as de riesgo significativas** entre reg√≠menes de mercado. La diversificaci√≥n tradicional colapsa en per√≠odos de crisis, con activos de alto rendimiento amplificando p√©rdidas (+150-200%) mientras que el oro proporciona protecci√≥n efectiva.\n",
      "\n",
      "**Recomendaci√≥n:** Revisar posiciones en bonos high-yield e incrementar exposici√≥n a activos refugio para optimizar ratio riesgo-retorno ajustado a din√°micas de r√©gimen.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute Phase 1\n",
    "if __name__ == \"__main__\":\n",
    "    ensure_directories()\n",
    "    set_global_seed()\n",
    "\n",
    "    portfolio_instance = build_portfolio()\n",
    "    market_data_df = market_risk()\n",
    "    regime_stats = run_regime_detection_pipeline()\n",
    "    \n",
    "    # Ensure regime detection results are available\n",
    "    if 'regime_stats' in locals():\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"INICIANDO FASE 1...\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "        \n",
    "        # Re-run regime detection to get all necessary variables\n",
    "        log_returns, sp500_prices = load_and_prepare_returns(COMBINED_PATH)\n",
    "        X_scaled, _, log_returns_clean = standardize_returns(log_returns)\n",
    "        model = fit_hmm(X_scaled, n_components=2)\n",
    "        regimes, hmm_results = identify_regimes(model, X_scaled)\n",
    "        \n",
    "        # Run Phase 1 analysis\n",
    "        df_stats, df_key_assets, df_vol_comparison, interpretation = run_phase1_risk_analysis(\n",
    "            portfolio_instance, regimes, log_returns_clean, hmm_results\n",
    "        )\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ESTAD√çSTICAS MARGINALES POR ACTIVO Y R√âGIMEN\")\n",
    "        print(\"=\" * 80)\n",
    "        print(df_stats.to_string(index=False))\n",
    "        print()\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"AN√ÅLISIS DETALLADO: ACTIVOS CLAVE (HYG, GLD)\")\n",
    "        print(\"=\" * 80)\n",
    "        print(df_key_assets.to_string(index=False))\n",
    "        print()\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"COMPARACI√ìN DE VOLATILIDAD: RATIO CRISIS/CALM\")\n",
    "        print(\"=\" * 80)\n",
    "        print(df_vol_comparison.to_string(index=False))\n",
    "        print()\n",
    "        \n",
    "        # Display the report\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"GENERANDO INFORME EJECUTIVO...\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "        executive_report = generate_executive_report(\n",
    "            regime_stats,\n",
    "            df_stats,\n",
    "            df_key_assets,\n",
    "            df_vol_comparison,\n",
    "            interpretation,\n",
    "            portfolio_instance,\n",
    "            regimes,\n",
    "            hmm_results,\n",
    "            REPORT_DIR\n",
    "        )\n",
    "\n",
    "        print(executive_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
