{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e76089",
   "metadata": {},
   "source": [
    "# PRÃCTICA B2-2 #\n",
    "\n",
    "## MÃ“DULO DE GESTIÃ“N DE RIESGOS ##\n",
    "### Escenarios de EstrÃ©s y Cambios de RÃ©gimen de Mercado ###\n",
    "\n",
    "### Datos bÃ¡sicos: ###\n",
    "- PrÃ¡ctica en grupos de dos personas\n",
    "- Entrega el dÃ­a 15 de febrero a travÃ©s del aula virtual.\n",
    "- Los entregables son un notebook de Python y un resumen ejecutivo en formato PDF.\n",
    "\n",
    "### Objetivo de la prÃ¡ctica ###\n",
    "El objetivo de esta prÃ¡ctica es rediseÃ±ar un motor de stress testing en Python capaz de\n",
    "capturar el riesgo de cola y los cambios de rÃ©gimen, identificar cuÃ¡ndo el mercado entra en\n",
    "â€œcrisisâ€ y cuantificar el riesgo real cuando la diversificaciÃ³n desaparece. El motor de\n",
    "simulaciÃ³n deberÃ¡ utilizarse explÃ­citamente para construir Escenarios de EstrÃ©s cuyo\n",
    "objetivo sea â€œromper la carteraâ€, forzando condiciones adversas y econÃ³micamente\n",
    "coherentes, y cuantificando pÃ©rdidas extremas mediante VaR del 99% y Expected Shortfall\n",
    "(CVaR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8791c8",
   "metadata": {},
   "source": [
    "### Fase 0 - Preparacion y Estructura del Proyecto ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7aae98",
   "metadata": {},
   "source": [
    "### Librerias ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff28ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from hmmlearn import hmm\n",
    "from pandas_datareader import data as pdr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats as sp_stats\n",
    "\n",
    "# For PDF generation\n",
    "try:\n",
    "    import markdown\n",
    "    from weasyprint import HTML, CSS\n",
    "    PDF_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PDF_AVAILABLE = False\n",
    "    print(\"Warning: markdown/weasyprint not available. PDF generation will be skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9658f1ef",
   "metadata": {},
   "source": [
    "### Variables ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b6e2898",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "BASE_DIR = Path(\"..\").resolve()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "DATA_BRONZE_DIR = DATA_DIR / \"bronze\"\n",
    "DATA_SILVER_DIR = DATA_DIR / \"silver\"\n",
    "DATA_GOLD_DIR = DATA_DIR / \"gold\"\n",
    "FIGURES_DIR = BASE_DIR / \"figures\"\n",
    "REPORT_DIR = BASE_DIR / \"report\"\n",
    "\n",
    "START_DATE = \"2006-01-01\"\n",
    "END_DATE = date.today().isoformat()\n",
    "\n",
    "COMBINED_PATH = DATA_GOLD_DIR / \"market_data_combined.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ed2b4",
   "metadata": {},
   "source": [
    "### Clases ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75b0ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MarketData:\n",
    "    \"\"\"Utility class for downloading and combining market data.\"\"\"\n",
    "\n",
    "    equities: List[str] = field(default_factory=list)\n",
    "    yields: List[str] = field(default_factory=list)\n",
    "\n",
    "    combined_data: pd.DataFrame = field(init=False)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        equity_data = (\n",
    "            self.fetch_equities(self.equities, start=START_DATE, end=END_DATE)\n",
    "            if self.equities\n",
    "            else pd.DataFrame()\n",
    "        )\n",
    "        yield_data = (\n",
    "            self.fetch_us_yields(self.yields, start=START_DATE, end=END_DATE)\n",
    "            if self.yields\n",
    "            else pd.DataFrame()\n",
    "        )\n",
    "        self.combined_data = self.combine_and_fill(equity_data, yield_data)\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_equities(tickers: List[str], start: str, end: str) -> pd.DataFrame:\n",
    "        \"\"\"Fetch adjusted close prices for a list of tickers using yfinance.\"\"\"\n",
    "        if not tickers:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        equities = yf.download(\n",
    "            tickers,\n",
    "            start=start,\n",
    "            end=end,\n",
    "            progress=False,\n",
    "            threads=True,\n",
    "            auto_adjust=True,\n",
    "        )[\"Close\"]\n",
    "\n",
    "        if isinstance(tickers, list):\n",
    "            tickers_join = \"_\".join(tickers)\n",
    "        else:\n",
    "            tickers_join = str(tickers)\n",
    "\n",
    "        DATA_BRONZE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        equities_path = DATA_BRONZE_DIR / f\"equities_adj_close_{tickers_join}.csv\"\n",
    "        equities.sort_index().to_csv(equities_path)\n",
    "\n",
    "        return equities.sort_index()\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_us_yields(tickers: Union[List[str], str], start: str, end: str) -> pd.DataFrame:\n",
    "        \"\"\"Fetch US yields from FRED.\"\"\"\n",
    "        if not tickers:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        yields = pdr.DataReader(tickers, \"fred\", start, end)\n",
    "        yields.index = pd.to_datetime(yields.index)\n",
    "\n",
    "        if isinstance(tickers, list):\n",
    "            tickers_join = \"_\".join(tickers)\n",
    "        else:\n",
    "            tickers_join = str(tickers)\n",
    "\n",
    "        DATA_BRONZE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        yields_path = DATA_BRONZE_DIR / f\"us_yields_{tickers_join}.csv\"\n",
    "        yields.sort_index().to_csv(yields_path)\n",
    "\n",
    "        return yields.sort_index()\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_and_fill(equities: pd.DataFrame, yields: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Combine equities and yields into a single DataFrame and forward-fill missing yield data.\"\"\"\n",
    "        combined = pd.concat([equities, yields], axis=1).sort_index()\n",
    "\n",
    "        # Forward-fill only yield series to avoid contaminating equity prices\n",
    "        for col in [\"GS10\", \"GS2\", \"BAMLH0A0HYM2\"]:\n",
    "            if col in combined.columns:\n",
    "                combined[col] = combined[col].ffill()\n",
    "\n",
    "        DATA_SILVER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        combined_path = DATA_SILVER_DIR / \"market_data_combined.csv\"\n",
    "        combined.to_csv(combined_path)\n",
    "\n",
    "        return combined\n",
    "\n",
    "@dataclass\n",
    "class Portfolio:\n",
    "    \"\"\"Equal-weight portfolio built from equities and yield instruments.\"\"\"\n",
    "\n",
    "    assets: Dict[str, str]\n",
    "\n",
    "    prices: pd.DataFrame = field(init=False)\n",
    "    returns: pd.DataFrame = field(init=False)\n",
    "    weights: pd.DataFrame = field(init=False)\n",
    "    portfolio_returns: pd.Series = field(init=False)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self._load_prices()\n",
    "        self._compute_returns()\n",
    "        self._compute_dynamic_weights()\n",
    "        self._compute_portfolio_returns()\n",
    "\n",
    "    def _load_prices(self) -> None:\n",
    "        equities = [\n",
    "            ticker for ticker, asset_type in self.assets.items() if asset_type == \"equity\"\n",
    "        ]\n",
    "        yields = [\n",
    "            ticker for ticker, asset_type in self.assets.items() if asset_type == \"yield\"\n",
    "        ]\n",
    "\n",
    "        equity_data = MarketData.fetch_equities(equities, start=START_DATE, end=END_DATE)\n",
    "        yield_data = MarketData.fetch_us_yields(yields, start=START_DATE, end=END_DATE)\n",
    "\n",
    "        self.prices = MarketData.combine_and_fill(equity_data, yield_data)\n",
    "\n",
    "    def _compute_returns(self) -> None:\n",
    "        # Daily simple returns without implicit forward-filling\n",
    "        self.returns = self.prices.pct_change(fill_method=None)\n",
    "\n",
    "    def _compute_dynamic_weights(self) -> None:\n",
    "        asset_exists = ~self.prices.isna()\n",
    "        n_assets = asset_exists.sum(axis=1)\n",
    "\n",
    "        self.weights = asset_exists.div(n_assets, axis=0).fillna(0.0)\n",
    "\n",
    "    def _compute_portfolio_returns(self) -> None:\n",
    "        self.portfolio_returns = (self.returns * self.weights).sum(axis=1)\n",
    "\n",
    "    def cumulative_return(self) -> pd.Series:\n",
    "        return (1 + self.portfolio_returns).cumprod()\n",
    "\n",
    "    def drawdown(self) -> pd.Series:\n",
    "        wealth = self.cumulative_return()\n",
    "        peak = wealth.cummax()\n",
    "        return (wealth - peak) / peak\n",
    "\n",
    "    def max_drawdown(self) -> float:\n",
    "        return float(self.drawdown().min())\n",
    "\n",
    "    def volatility(self, annualized: bool = True) -> float:\n",
    "        vol = float(self.portfolio_returns.std())\n",
    "        return vol * np.sqrt(252) if annualized else vol\n",
    "\n",
    "    def mean_return(self, annualized: bool = True) -> float:\n",
    "        mu = float(self.portfolio_returns.mean())\n",
    "        return mu * 252 if annualized else mu\n",
    "\n",
    "    def sharpe_ratio(self) -> float:\n",
    "        return self.mean_return() / self.volatility()\n",
    "\n",
    "    def var_cvar(self, alpha: float = 0.99) -> Tuple[float, float]:\n",
    "        var = float(self.portfolio_returns.quantile(1 - alpha))\n",
    "        cvar = float(self.portfolio_returns[self.portfolio_returns <= var].mean())\n",
    "        return var, cvar\n",
    "\n",
    "    def summary(self) -> pd.Series:\n",
    "        var_99, cvar_99 = self.var_cvar(0.99)\n",
    "\n",
    "        return pd.Series(\n",
    "            {\n",
    "                \"Mean Return (ann)\": self.mean_return(),\n",
    "                \"Volatility (ann)\": self.volatility(),\n",
    "                \"Sharpe\": self.sharpe_ratio(),\n",
    "                \"Max Drawdown\": self.max_drawdown(),\n",
    "                \"VaR 99%\": var_99,\n",
    "                \"CVaR 99%\": cvar_99,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def portfolio_composition_table(self) -> pd.DataFrame:\n",
    "        weights_pct = self.weights * 100\n",
    "        asset_values = self.prices * self.weights\n",
    "\n",
    "        data: Dict[Tuple[str, str], pd.Series] = {}\n",
    "        for asset in self.prices.columns:\n",
    "            data[(asset, \"weight_%\")] = weights_pct[asset]\n",
    "            data[(asset, \"price\")] = self.prices[asset]\n",
    "            data[(asset, \"value\")] = asset_values[asset]\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.columns = pd.MultiIndex.from_tuples(df.columns)\n",
    "\n",
    "        df[\"portfolio_value\"] = asset_values.sum(axis=1)\n",
    "        df[\"portfolio_return_%\"] = df[\"portfolio_value\"].pct_change() * 100\n",
    "\n",
    "        DATA_GOLD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        portfolio_table_path = DATA_GOLD_DIR / \"portfolio_composition.csv\"\n",
    "        df.to_csv(portfolio_table_path)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def plot_portfolio(self) -> None:\n",
    "        cumulative_returns = self.cumulative_return()\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        sns.lineplot(data=cumulative_returns)\n",
    "        plt.title(\"Cumulative Return of the Portfolio\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Cumulative Return\")\n",
    "        plt.tight_layout()\n",
    "        FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        chart_path = FIGURES_DIR / \"portfolio_returns_chart.png\"\n",
    "        plt.savefig(chart_path)\n",
    "        plt.close()\n",
    "\n",
    "    def plot_chart_per_asset(self) -> None:\n",
    "        FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        for col in self.prices.columns:\n",
    "            plt.figure(figsize=(10, 3))\n",
    "            sns.lineplot(data=self.prices[col])\n",
    "            plt.title(f\"{col} Price Over Time\")\n",
    "            plt.xlabel(\"Date\")\n",
    "            plt.ylabel(\"Price\")\n",
    "            plt.tight_layout()\n",
    "            chart_path = FIGURES_DIR / f\"{col}_price_chart.png\"\n",
    "            plt.savefig(chart_path)\n",
    "            plt.close()\n",
    "\n",
    "@dataclass\n",
    "class HMMState:\n",
    "    \"\"\"Parameters of a single HMM state.\"\"\"\n",
    "\n",
    "    mean: np.ndarray\n",
    "    cov: np.ndarray\n",
    "    volatility: float  # Frobenius norm of covariance diagonal\n",
    "\n",
    "@dataclass\n",
    "class HMMResults:\n",
    "    \"\"\"Fitted HMM results and regime assignments.\"\"\"\n",
    "\n",
    "    model: hmm.GaussianHMM\n",
    "    transition_matrix: np.ndarray\n",
    "    states: Dict[int, HMMState]\n",
    "    regimes: np.ndarray  # regime_t for each time step\n",
    "    calm_state: int  # which state index corresponds to \"calm\"\n",
    "    crisis_state: int  # which state index corresponds to \"crisis\"\n",
    "\n",
    "@dataclass\n",
    "class RegimeCopula:\n",
    "    \"\"\"Copula parameters for a given regime (simple Gaussian copula).\"\"\"\n",
    "\n",
    "    regime_name: str\n",
    "    assets: List[str]\n",
    "    correlation: pd.DataFrame  # correlation matrix in asset order\n",
    "\n",
    "    def sample(self, n_samples: int, random_state: Union[int, None] = None) -> np.ndarray:\n",
    "        \"\"\"Draw samples from the copula in standard normal space.\"\"\"\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        cov = self.correlation.values\n",
    "        chol = np.linalg.cholesky(cov)\n",
    "        z = rng.standard_normal(size=(n_samples, len(self.assets)))\n",
    "        return z @ chol.T\n",
    "\n",
    "@dataclass\n",
    "class RegimeMonteCarloSimulator:\n",
    "    \"\"\"Monte Carlo engine driven by HMM regimes and copulas.\"\"\"\n",
    "\n",
    "    transition_matrix: np.ndarray  # from HMM\n",
    "    assets: List[str]\n",
    "    regime_marginals: Dict[str, pd.DataFrame]  # output of calculate_marginal_statistics\n",
    "    regime_copulas: Dict[str, RegimeCopula]\n",
    "\n",
    "    def _simulate_regime_paths(\n",
    "        self,\n",
    "        n_paths: int,\n",
    "        n_steps: int,\n",
    "        initial_state: int,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Simulate Markov regime paths using the HMM transition matrix.\"\"\"\n",
    "        rng = np.random.default_rng(RANDOM_SEED)\n",
    "        regimes = np.empty((n_paths, n_steps), dtype=int)\n",
    "        regimes[:, 0] = initial_state\n",
    "\n",
    "        for t in range(1, n_steps):\n",
    "            for p in range(n_paths):\n",
    "                current = regimes[p, t - 1]\n",
    "                probs = self.transition_matrix[current]\n",
    "                regimes[p, t] = rng.choice(len(probs), p=probs)\n",
    "\n",
    "        return regimes\n",
    "\n",
    "    def _get_marginals_for_regime(self, regime_label: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Return mean and volatility vectors aligned with self.assets for a regime.\"\"\"\n",
    "        stats_df = self.regime_marginals[regime_label]\n",
    "        means = np.array(\n",
    "            [stats_df.loc[stats_df[\"Asset\"] == a, \"Mean Return\"].iloc[0] for a in self.assets]\n",
    "        )\n",
    "        vols = np.array(\n",
    "            [stats_df.loc[stats_df[\"Asset\"] == a, \"Volatility\"].iloc[0] for a in self.assets]\n",
    "        )\n",
    "        return means, vols\n",
    "\n",
    "    def simulate_returns(\n",
    "        self,\n",
    "        n_paths: int,\n",
    "        n_steps: int,\n",
    "        initial_state: int,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Simulate multi-asset returns and corresponding regime paths.\"\"\"\n",
    "        regimes = self._simulate_regime_paths(n_paths, n_steps, initial_state)\n",
    "        n_assets = len(self.assets)\n",
    "        simulated = np.zeros((n_paths, n_steps, n_assets), dtype=float)\n",
    "\n",
    "        state_to_label = {0: \"CALM\", 1: \"CRISIS\"}\n",
    "        rng = np.random.default_rng(RANDOM_SEED + 1)\n",
    "\n",
    "        for p in range(n_paths):\n",
    "            for t in range(n_steps):\n",
    "                numeric_state = regimes[p, t]\n",
    "                regime_label = state_to_label[numeric_state]\n",
    "\n",
    "                if regime_label not in self.regime_copulas:\n",
    "                    continue\n",
    "\n",
    "                copula = self.regime_copulas[regime_label]\n",
    "                means, vols = self._get_marginals_for_regime(regime_label)\n",
    "\n",
    "                z = copula.sample(1, random_state=rng.integers(0, 1_000_000))[0]\n",
    "                simulated[p, t, :] = means + vols * z\n",
    "\n",
    "        return simulated, regimes\n",
    "\n",
    "@dataclass\n",
    "class StressScenario:\n",
    "    \"\"\"Configuration for a stress-testing scenario in Phase 5.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    description: str\n",
    "    transition_matrix: np.ndarray\n",
    "    volatility_multipliers: Dict[str, float]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee03872",
   "metadata": {},
   "source": [
    "### Funciones ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205487e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_global_seed() -> None:\n",
    "    \"\"\"Set global random seed for reproducibility.\"\"\"\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def ensure_directories() -> None:\n",
    "    \"\"\"Create all necessary directories for the project.\"\"\"\n",
    "    DATA_BRONZE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    DATA_SILVER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    DATA_GOLD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "# FASE 0 - GET DATA\n",
    "# =============================================================================\n",
    "def yield_curve_slope(y10: pd.Series, y2: pd.Series) -> pd.Series:\n",
    "    \"\"\"Calculate the yield curve slope (10Y - 2Y spread).\"\"\"\n",
    "    return y10 - y2\n",
    "\n",
    "def portfolio() -> Portfolio:\n",
    "    \"\"\"Create the baseline multi-asset portfolio configuration and return a Portfolio.\"\"\"\n",
    "\n",
    "    assets: Dict[str, str] = {\n",
    "        \"AAPL\": \"equity\",\n",
    "        \"AMZN\": \"equity\",\n",
    "        \"BAC\": \"equity\",\n",
    "        \"BRK-B\": \"equity\",\n",
    "        \"CVX\": \"equity\",\n",
    "        \"ENPH\": \"equity\",\n",
    "        \"GLD\": \"equity\",\n",
    "        \"GME\": \"equity\",\n",
    "        \"GOOGL\": \"equity\",\n",
    "        \"JNJ\": \"equity\",\n",
    "        \"JPM\": \"equity\",\n",
    "        \"MSFT\": \"equity\",\n",
    "        \"NVDA\": \"equity\",\n",
    "        \"PG\": \"equity\",\n",
    "        \"XOM\": \"equity\",\n",
    "        \"HYG\": \"equity\",\n",
    "        \"GS10\": \"yield\",\n",
    "        \"GS2\": \"yield\",\n",
    "    }\n",
    "\n",
    "    return Portfolio(assets=assets)\n",
    "\n",
    "def market_risk() -> pd.DataFrame:\n",
    "    \"\"\"Construct the market risk data set used for regime detection.\"\"\"\n",
    "\n",
    "    # Equity market\n",
    "    sp500 = MarketData.fetch_equities(tickers=[\"^GSPC\"], start=START_DATE, end=END_DATE)\n",
    "    sp500_ret = sp500.pct_change(fill_method=None)\n",
    "\n",
    "    vix = MarketData.fetch_equities(tickers=[\"^VIX\"], start=START_DATE, end=END_DATE)\n",
    "    vix_ret = vix.pct_change(fill_method=None)\n",
    "\n",
    "    # Interest rates\n",
    "    y10 = MarketData.fetch_us_yields(\"GS10\", start=START_DATE, end=END_DATE)\n",
    "    y2 = MarketData.fetch_us_yields(\"GS2\", start=START_DATE, end=END_DATE)\n",
    "\n",
    "    y10_chg = y10.pct_change(fill_method=None)\n",
    "    y2_chg = y2.pct_change(fill_method=None)\n",
    "    slope = yield_curve_slope(y10[\"GS10\"], y2[\"GS2\"]).rename(\"yield_slope\")\n",
    "\n",
    "    # Credit spread\n",
    "    hy_spread = MarketData.fetch_us_yields(\"BAMLH0A0HYM2\", start=START_DATE, end=END_DATE)\n",
    "    hy_spread_chg = hy_spread.pct_change(fill_method=None)\n",
    "\n",
    "    # Combine all market risk drivers\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            sp500_ret,\n",
    "            vix_ret,\n",
    "            y10_chg,\n",
    "            y2_chg,\n",
    "            slope,\n",
    "            hy_spread_chg,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    for col in [\"GS10\", \"GS2\", \"yield_slope\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].ffill()\n",
    "\n",
    "    DATA_GOLD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    df_path = DATA_GOLD_DIR / \"market_data_combined.csv\"\n",
    "    df.to_csv(df_path)\n",
    "\n",
    "    return df\n",
    "\n",
    "# =============================================================================\n",
    "# FASE 1 - Detectando el \"Pulso\" del Mercado (Hidden Markov Models)\n",
    "# =============================================================================#Fase 1\n",
    "def separate_data_by_regime(\n",
    "    portfolio: Portfolio,\n",
    "    regimes: np.ndarray,\n",
    "    log_returns_clean: pd.DataFrame,\n",
    "    hmm_results: HMMResults\n",
    ") -> Tuple[Dict[str, pd.DataFrame], Dict[str, pd.DataFrame]]:\n",
    "    \"\"\"Separate portfolio returns and asset prices by regime.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    portfolio : Portfolio\n",
    "        Portfolio object with prices and returns.\n",
    "    regimes : np.ndarray\n",
    "        Regime assignments.\n",
    "    log_returns_clean : pd.DataFrame\n",
    "        Cleaned log returns aligned with regimes.\n",
    "    hmm_results : HMMResults\n",
    "        HMM results with state labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Dict[str, pd.DataFrame], Dict[str, pd.DataFrame]]\n",
    "        Returns and prices separated by regime.\n",
    "    \"\"\"\n",
    "    # Align portfolio returns with cleaned log returns index\n",
    "    portfolio_returns_clean = portfolio.portfolio_returns.loc[log_returns_clean.index]\n",
    "    \n",
    "    # Separate data by regime\n",
    "    calm_mask = regimes == hmm_results.calm_state\n",
    "    crisis_mask = regimes == hmm_results.crisis_state\n",
    "    \n",
    "    returns_by_regime = {\n",
    "        \"CALM\": portfolio_returns_clean[calm_mask],\n",
    "        \"CRISIS\": portfolio_returns_clean[crisis_mask]\n",
    "    }\n",
    "    \n",
    "    # Separate asset returns by regime\n",
    "    asset_returns_by_regime = {\n",
    "        \"CALM\": portfolio.returns.loc[log_returns_clean.index][calm_mask],\n",
    "        \"CRISIS\": portfolio.returns.loc[log_returns_clean.index][crisis_mask]\n",
    "    }\n",
    "    \n",
    "    return returns_by_regime, asset_returns_by_regime\n",
    "\n",
    "def calculate_marginal_statistics(\n",
    "    asset_returns: Dict[str, pd.DataFrame],\n",
    "    assets: Dict[str, str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Calculate marginal statistics (mean, vol, skewness, kurtosis) by regime and asset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    asset_returns : Dict[str, pd.DataFrame]\n",
    "        Asset returns separated by regime.\n",
    "    assets : Dict[str, str]\n",
    "        Asset dictionary with types.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Comprehensive statistics table by asset and regime.\n",
    "    \"\"\"\n",
    "    stats_list = []\n",
    "    \n",
    "    for regime_name, returns_df in asset_returns.items():\n",
    "        for asset in returns_df.columns:\n",
    "            if asset in assets:\n",
    "                asset_ret = returns_df[asset].dropna()\n",
    "                \n",
    "                if len(asset_ret) > 0:\n",
    "                    mean_ret = asset_ret.mean()\n",
    "                    volatility = asset_ret.std()\n",
    "                    skewness = sp_stats.skew(asset_ret)\n",
    "                    kurtosis = sp_stats.kurtosis(asset_ret)\n",
    "                    \n",
    "                    stats_list.append({\n",
    "                        \"Asset\": asset,\n",
    "                        \"Regime\": regime_name,\n",
    "                        \"Mean Return\": mean_ret,\n",
    "                        \"Volatility\": volatility,\n",
    "                        \"Skewness\": skewness,\n",
    "                        \"Kurtosis\": kurtosis,\n",
    "                        \"N Obs\": len(asset_ret)\n",
    "                    })\n",
    "    \n",
    "    df_stats = pd.DataFrame(stats_list)\n",
    "    return df_stats.sort_values([\"Asset\", \"Regime\"]).reset_index(drop=True)\n",
    "\n",
    "def analyze_key_assets(\n",
    "    asset_returns: Dict[str, pd.DataFrame],\n",
    "    key_assets: List[str] = [\"HYG\", \"GLD\"]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Focus analysis on key assets (High Yield, Gold).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    asset_returns : Dict[str, pd.DataFrame]\n",
    "        Asset returns separated by regime.\n",
    "    key_assets : List[str]\n",
    "        List of key assets to analyze.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Detailed statistics for key assets.\n",
    "    \"\"\"\n",
    "    key_stats = []\n",
    "    \n",
    "    for asset in key_assets:\n",
    "        for regime_name, returns_df in asset_returns.items():\n",
    "            if asset in returns_df.columns:\n",
    "                asset_ret = returns_df[asset].dropna()\n",
    "                \n",
    "                if len(asset_ret) > 0:\n",
    "                    var_99 = asset_ret.quantile(0.01)  # 1% worst case\n",
    "                    cvar_99 = asset_ret[asset_ret <= var_99].mean()\n",
    "                    \n",
    "                    key_stats.append({\n",
    "                        \"Asset\": asset,\n",
    "                        \"Regime\": regime_name,\n",
    "                        \"Mean (%)\": asset_ret.mean() * 100,\n",
    "                        \"Volatility (%)\": asset_ret.std() * 100,\n",
    "                        \"Skewness\": sp_stats.skew(asset_ret),\n",
    "                        \"Kurtosis\": sp_stats.kurtosis(asset_ret),\n",
    "                        \"VaR 99%\": var_99,\n",
    "                        \"CVaR 99%\": cvar_99,\n",
    "                        \"Min Return\": asset_ret.min(),\n",
    "                        \"Max Return\": asset_ret.max(),\n",
    "                    })\n",
    "    \n",
    "    df_key = pd.DataFrame(key_stats)\n",
    "    return df_key.sort_values([\"Asset\", \"Regime\"]).reset_index(drop=True)\n",
    "\n",
    "def interpret_regime_changes(df_key_assets: pd.DataFrame) -> str:\n",
    "    \"\"\"Generate economic interpretation of regime changes for key assets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_key_assets : pd.DataFrame\n",
    "        Key assets statistics by regime.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Interpretation text.\n",
    "    \"\"\"\n",
    "    interpretation = []\n",
    "    interpretation.append(\"=\" * 80)\n",
    "    interpretation.append(\"INTERPRETACIÃ“N ECONÃ“MICA DE CAMBIOS DE RÃ‰GIMEN\")\n",
    "    interpretation.append(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    # HYG Analysis\n",
    "    hyg_calm = df_key_assets[(df_key_assets[\"Asset\"] == \"HYG\") & (df_key_assets[\"Regime\"] == \"CALM\")]\n",
    "    hyg_crisis = df_key_assets[(df_key_assets[\"Asset\"] == \"HYG\") & (df_key_assets[\"Regime\"] == \"CRISIS\")]\n",
    "    \n",
    "    if not hyg_calm.empty and not hyg_crisis.empty:\n",
    "        vol_calm = hyg_calm[\"Volatility (%)\"].values[0]\n",
    "        vol_crisis = hyg_crisis[\"Volatility (%)\"].values[0]\n",
    "        vol_change = ((vol_crisis - vol_calm) / vol_calm) * 100\n",
    "        \n",
    "        interpretation.append(\"ðŸ“Š HIGH YIELD (HYG) - Bonos de Alto Rendimiento\")\n",
    "        interpretation.append(\"-\" * 80)\n",
    "        interpretation.append(f\"  â€¢ Volatilidad en CALMA: {vol_calm:.2f}%\")\n",
    "        interpretation.append(f\"  â€¢ Volatilidad en CRISIS: {vol_crisis:.2f}%\")\n",
    "        interpretation.append(f\"  â€¢ Aumento: {vol_change:.1f}%\")\n",
    "        interpretation.append(\"\\n  INTERPRETACIÃ“N:\")\n",
    "        interpretation.append(\"  El aumento de volatilidad en crisis refleja:\")\n",
    "        interpretation.append(\"  âœ“ Mayor aversiÃ³n al riesgo en el mercado\")\n",
    "        interpretation.append(\"  âœ“ Widening de spreads de crÃ©dito\")\n",
    "        interpretation.append(\"  âœ“ Stress en el segmento de bonos de alto rendimiento\")\n",
    "        interpretation.append(\"  â†’ El HYG es PRO-CÃCLICO (amplifica riesgo en crisis)\\n\")\n",
    "    \n",
    "    # GLD Analysis\n",
    "    gld_calm = df_key_assets[(df_key_assets[\"Asset\"] == \"GLD\") & (df_key_assets[\"Regime\"] == \"CALM\")]\n",
    "    gld_crisis = df_key_assets[(df_key_assets[\"Asset\"] == \"GLD\") & (df_key_assets[\"Regime\"] == \"CRISIS\")]\n",
    "    \n",
    "    if not gld_calm.empty and not gld_crisis.empty:\n",
    "        ret_calm = gld_calm[\"Mean (%)\"].values[0]\n",
    "        ret_crisis = gld_crisis[\"Mean (%)\"].values[0]\n",
    "        vol_calm_gld = gld_calm[\"Volatility (%)\"].values[0]\n",
    "        vol_crisis_gld = gld_crisis[\"Volatility (%)\"].values[0]\n",
    "        \n",
    "        interpretation.append(\"ðŸ† ORO (GLD) - Activo Refugio\")\n",
    "        interpretation.append(\"-\" * 80)\n",
    "        interpretation.append(f\"  â€¢ Retorno medio en CALMA: {ret_calm:.2f}%\")\n",
    "        interpretation.append(f\"  â€¢ Retorno medio en CRISIS: {ret_crisis:.2f}%\")\n",
    "        interpretation.append(f\"  â€¢ Volatilidad en CALMA: {vol_calm_gld:.2f}%\")\n",
    "        interpretation.append(f\"  â€¢ Volatilidad en CRISIS: {vol_crisis_gld:.2f}%\")\n",
    "        \n",
    "        if ret_crisis > ret_calm:\n",
    "            interpretation.append(\"\\n  INTERPRETACIÃ“N:\")\n",
    "            interpretation.append(\"  âœ“ El ORO SUBE durante crisis (comportamiento de refugio)\")\n",
    "            interpretation.append(\"  âœ“ Inversores huyen a activos seguros\")\n",
    "            interpretation.append(\"  âœ“ Cobertura contra inflaciÃ³n y depreciaciÃ³n de divisas\")\n",
    "            interpretation.append(\"  â†’ El GLD es ANTI-CÃCLICO (protecciÃ³n en turbulencia)\\n\")\n",
    "        else:\n",
    "            interpretation.append(\"\\n  INTERPRETACIÃ“N:\")\n",
    "            interpretation.append(\"  âš  El ORO NO actÃºa como refugio esperado\")\n",
    "            interpretation.append(\"  âš  Posible liquidaciÃ³n forzada en crisis\")\n",
    "            interpretation.append(\"  â†’ Revisar correlaciÃ³n con equity en stress\\n\")\n",
    "    \n",
    "    interpretation.append(\"=\" * 80)\n",
    "    return \"\\n\".join(interpretation)\n",
    "\n",
    "def compare_volatility_regimes(df_stats: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create comparison table of volatility changes between regimes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_stats : pd.DataFrame\n",
    "        Statistics by asset and regime.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Volatility comparison table.\n",
    "    \"\"\"\n",
    "    vol_comparison = []\n",
    "    \n",
    "    for asset in df_stats[\"Asset\"].unique():\n",
    "        asset_data = df_stats[df_stats[\"Asset\"] == asset]\n",
    "        \n",
    "        calm_vol = asset_data[asset_data[\"Regime\"] == \"CALM\"][\"Volatility\"].values\n",
    "        crisis_vol = asset_data[asset_data[\"Regime\"] == \"CRISIS\"][\"Volatility\"].values\n",
    "        \n",
    "        if len(calm_vol) > 0 and len(crisis_vol) > 0:\n",
    "            vol_ratio = crisis_vol[0] / calm_vol[0]\n",
    "            vol_change = ((crisis_vol[0] - calm_vol[0]) / calm_vol[0]) * 100\n",
    "            \n",
    "            vol_comparison.append({\n",
    "                \"Asset\": asset,\n",
    "                \"Volatility CALM\": calm_vol[0],\n",
    "                \"Volatility CRISIS\": crisis_vol[0],\n",
    "                \"Ratio (Crisis/Calm)\": vol_ratio,\n",
    "                \"% Change\": vol_change\n",
    "            })\n",
    "    \n",
    "    df_vol = pd.DataFrame(vol_comparison)\n",
    "    return df_vol.sort_values(\"Ratio (Crisis/Calm)\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "def save_phase1_analysis(\n",
    "    df_stats: pd.DataFrame,\n",
    "    df_key_assets: pd.DataFrame,\n",
    "    df_vol_comparison: pd.DataFrame,\n",
    "    interpretation: str,\n",
    "    output_dir: Path\n",
    ") -> None:\n",
    "    \"\"\"Save all Phase 1 analysis results to files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_stats : pd.DataFrame\n",
    "        Marginal statistics table.\n",
    "    df_key_assets : pd.DataFrame\n",
    "        Key assets analysis.\n",
    "    df_vol_comparison : pd.DataFrame\n",
    "        Volatility comparison.\n",
    "    interpretation : str\n",
    "        Economic interpretation text.\n",
    "    output_dir : Path\n",
    "        Output directory path.\n",
    "    \"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save statistics tables\n",
    "    df_stats.to_csv(output_dir / \"phase1_marginal_statistics.csv\", index=False)\n",
    "    df_key_assets.to_csv(output_dir / \"phase1_key_assets_analysis.csv\", index=False)\n",
    "    df_vol_comparison.to_csv(output_dir / \"phase1_volatility_comparison.csv\", index=False)\n",
    "    \n",
    "    # Save interpretation with UTF-8 encoding\n",
    "    with open(output_dir / \"phase1_interpretation.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(interpretation)\n",
    "\n",
    "def run_phase1_risk_analysis(\n",
    "    portfolio: Portfolio,\n",
    "    regimes: np.ndarray,\n",
    "    log_returns_clean: pd.DataFrame,\n",
    "    hmm_results: HMMResults\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, str]:\n",
    "    \"\"\"Execute complete Phase 1 analysis: Risk by Regime.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    portfolio : Portfolio\n",
    "        Portfolio object with prices and returns.\n",
    "    regimes : np.ndarray\n",
    "        Regime assignments.\n",
    "    log_returns_clean : pd.DataFrame\n",
    "        Cleaned log returns aligned with regimes.\n",
    "    hmm_results : HMMResults\n",
    "        HMM results with state labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, str]\n",
    "        Marginal statistics, key assets analysis, volatility comparison, and interpretation.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"FASE 1: ANÃLISIS DE RIESGO INDIVIDUAL POR RÃ‰GIMEN\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    # Task 1.1: Separate data by regime\n",
    "    print(\"1.1 Separando datos por rÃ©gimen...\")\n",
    "    returns_by_regime, asset_returns_by_regime = separate_data_by_regime(\n",
    "        portfolio, regimes, log_returns_clean, hmm_results\n",
    "    )\n",
    "    \n",
    "    calm_obs = len(returns_by_regime[\"CALM\"])\n",
    "    crisis_obs = len(returns_by_regime[\"CRISIS\"])\n",
    "    print(f\"     âœ“ DÃ­as en CALMA: {calm_obs}\")\n",
    "    print(f\"     âœ“ DÃ­as en CRISIS: {crisis_obs}\\n\")\n",
    "    \n",
    "    # Task 1.2: Calculate marginal statistics\n",
    "    print(\"1.2 Calculando estadÃ­sticas marginales...\")\n",
    "    df_stats = calculate_marginal_statistics(asset_returns_by_regime, portfolio.assets)\n",
    "    print(f\"     âœ“ {len(df_stats)} filas de estadÃ­sticas (activos Ã— regÃ­menes)\\n\")\n",
    "    \n",
    "    # Task 1.3: Analyze key assets\n",
    "    print(\"1.3 Analizando activos clave (HYG, GLD)...\")\n",
    "    df_key_assets = analyze_key_assets(asset_returns_by_regime)\n",
    "    print(f\"     âœ“ AnÃ¡lisis detallado de {df_key_assets['Asset'].nunique()} activos\\n\")\n",
    "    \n",
    "    # Volatility comparison\n",
    "    print(\"1.4 Comparando volatilidades entre regÃ­menes...\")\n",
    "    df_vol_comparison = compare_volatility_regimes(df_stats)\n",
    "    print(f\"     âœ“ Tabla de comparaciÃ³n creada\\n\")\n",
    "    \n",
    "    # Task 1.4: Economic interpretation\n",
    "    print(\"1.4 Generando interpretaciÃ³n econÃ³mica...\")\n",
    "    interpretation = interpret_regime_changes(df_key_assets)\n",
    "    print(interpretation)\n",
    "    print()\n",
    "    \n",
    "    # Save results\n",
    "    print(\"Guardando resultados de Fase 1...\")\n",
    "    save_phase1_analysis(df_stats, df_key_assets, df_vol_comparison, interpretation, DATA_GOLD_DIR)\n",
    "    print(f\"     âœ“ Resultados guardados en {DATA_GOLD_DIR}\\n\")\n",
    "    \n",
    "    return df_stats, df_key_assets, df_vol_comparison, interpretation\n",
    "\n",
    "# =============================================================================\n",
    "# FASE 2 -  AnatomÃ­a del Riesgo (AnÃ¡lisis Marginal)\n",
    "# =============================================================================\n",
    "def load_and_prepare_returns(data_path: Path) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Load combined market data and prepare log returns for HMM.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : Path\n",
    "        Path to the combined market data CSV file.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[pd.DataFrame, pd.Series]\n",
    "        Log returns DataFrame and S&P 500 price series.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_path, index_col=0, parse_dates=True)\n",
    "    \n",
    "    # Calculate log returns from the returns data\n",
    "    log_returns = df.copy()\n",
    "    \n",
    "    # Load original S&P 500 prices from Bronze directory for visualization\n",
    "    sp500_bronze_path = DATA_BRONZE_DIR / \"equities_adj_close_^GSPC.csv\"\n",
    "    if sp500_bronze_path.exists():\n",
    "        sp500_prices_raw = pd.read_csv(sp500_bronze_path, index_col=0, parse_dates=True)\n",
    "        # The column name should be the ticker itself\n",
    "        sp500_prices = sp500_prices_raw.iloc[:, 0]  # Get first column regardless of name\n",
    "    else:\n",
    "        # Fallback: reconstruct from returns if Bronze file not available\n",
    "        sp500_prices = pd.Series(index=log_returns.index, dtype=float)\n",
    "    \n",
    "    return log_returns, sp500_prices\n",
    "\n",
    "def standardize_returns(log_returns: pd.DataFrame) -> Tuple[np.ndarray, StandardScaler, pd.DataFrame]:\n",
    "    \"\"\"Standardize log returns using StandardScaler.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    log_returns : pd.DataFrame\n",
    "        DataFrame with log returns.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, StandardScaler, pd.DataFrame]\n",
    "        Scaled returns array, fitted scaler object, and cleaned returns DataFrame.\n",
    "    \"\"\"\n",
    "    # Remove rows with NaN or infinity values\n",
    "    log_returns_clean = log_returns.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(log_returns_clean)\n",
    "    return X_scaled, scaler, log_returns_clean\n",
    "\n",
    "def save_hmm_parameters(hmm_results: HMMResults, output_path: Path) -> None:\n",
    "    \"\"\"Save HMM parameters to text file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hmm_results : HMMResults\n",
    "        HMM results container.\n",
    "    output_path : Path\n",
    "        Path to save parameters file.\n",
    "    \"\"\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        f.write(\"HMM PARAMETERS\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"TRANSITION MATRIX:\\n\")\n",
    "        f.write(str(hmm_results.transition_matrix) + \"\\n\\n\")\n",
    "        \n",
    "        for state_idx, state in hmm_results.states.items():\n",
    "            state_label = \"CALM\" if state_idx == hmm_results.calm_state else \"CRISIS\"\n",
    "            f.write(f\"\\nSTATE {state_idx} ({state_label}):\\n\")\n",
    "            f.write(f\"  Volatility: {state.volatility:.6f}\\n\")\n",
    "            f.write(f\"  Mean:\\n{state.mean}\\n\")\n",
    "            f.write(f\"  Covariance (diagonal):\\n{np.diag(state.cov)}\\n\")\n",
    "\n",
    "def analyze_hmm_features(log_returns: pd.DataFrame, hmm_results: HMMResults) -> pd.DataFrame:\n",
    "    \"\"\"Analyze the contribution of each market variable to regime detection.\n",
    "    \n",
    "    Shows the mean returns and volatility per feature in each HMM state\n",
    "    (Calm vs Crisis), demonstrating that all market variables are being used.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    log_returns : pd.DataFrame\n",
    "        The multivariate log-returns DataFrame (all market variables).\n",
    "    hmm_results : HMMResults\n",
    "        Fitted HMM results containing state parameters.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Analysis table showing mean and std for each feature in each state.\n",
    "    \"\"\"\n",
    "    \n",
    "    analysis_data = []\n",
    "    \n",
    "    for state_idx, state in hmm_results.states.items():\n",
    "        state_name = \"CALM\" if state_idx == hmm_results.calm_state else \"CRISIS\"\n",
    "        \n",
    "        for col_idx, col_name in enumerate(log_returns.columns):\n",
    "            analysis_data.append({\n",
    "                \"Variable\": col_name,\n",
    "                \"Regime\": state_name,\n",
    "                \"Mean (HMM)\": state.mean[col_idx],\n",
    "                \"Std Dev (HMM)\": np.sqrt(state.cov[col_idx, col_idx]),\n",
    "            })\n",
    "    \n",
    "    df_analysis = pd.DataFrame(analysis_data)\n",
    "    return df_analysis.sort_values([\"Variable\", \"Regime\"]).reset_index(drop=True)\n",
    "\n",
    "def identify_regimes(model: hmm.GaussianHMM, X_scaled: np.ndarray) -> Tuple[np.ndarray, HMMResults]:\n",
    "    \"\"\"Identify market regimes using fitted HMM.\n",
    "    \n",
    "    Determines which state is \"calm\" and which is \"crisis\" based on volatility levels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : hmm.GaussianHMM\n",
    "        Fitted HMM model.\n",
    "    X_scaled : np.ndarray\n",
    "        Scaled multivariate returns.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, HMMResults]\n",
    "        Regime assignments and full HMM results container.\n",
    "    \"\"\"\n",
    "    regimes = model.predict(X_scaled)\n",
    "    \n",
    "    # Determine which state is calm vs crisis based on volatility\n",
    "    state_volatilities = []\n",
    "    for i in range(model.n_components):\n",
    "        vol = np.sqrt(np.trace(model.covars_[i]) / model.n_features)\n",
    "        state_volatilities.append(vol)\n",
    "    \n",
    "    calm_state = int(np.argmin(state_volatilities))\n",
    "    crisis_state = 1 - calm_state\n",
    "    \n",
    "    # Build state parameters\n",
    "    states = {}\n",
    "    for i in range(model.n_components):\n",
    "        states[i] = HMMState(\n",
    "            mean=model.means_[i],\n",
    "            cov=model.covars_[i],\n",
    "            volatility=state_volatilities[i]\n",
    "        )\n",
    "    \n",
    "    hmm_results = HMMResults(\n",
    "        model=model,\n",
    "        transition_matrix=model.transmat_,\n",
    "        states=states,\n",
    "        regimes=regimes,\n",
    "        calm_state=calm_state,\n",
    "        crisis_state=crisis_state\n",
    "    )\n",
    "    \n",
    "    return regimes, hmm_results\n",
    "\n",
    "def visualize_regimes(\n",
    "    prices: pd.Series,\n",
    "    regimes: np.ndarray,\n",
    "    calm_state: int,\n",
    "    crisis_state: int,\n",
    "    plot_path: Path\n",
    ") -> None:\n",
    "    \"\"\"Visualize price series with regime coloring.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prices : pd.Series\n",
    "        Price series to plot.\n",
    "    regimes : np.ndarray\n",
    "        Regime assignments.\n",
    "    calm_state : int\n",
    "        Index of calm regime.\n",
    "    crisis_state : int\n",
    "        Index of crisis regime.\n",
    "    plot_path : Path\n",
    "        Path to save the figure.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    \n",
    "    # Plot prices\n",
    "    ax.plot(prices.index, prices.values, \"k-\", linewidth=1.5, label=\"S&P 500 Price\")\n",
    "    \n",
    "    # Color background by regime\n",
    "    for i in range(len(regimes) - 1):\n",
    "        if regimes[i] == calm_state:\n",
    "            ax.axvspan(prices.index[i], prices.index[i + 1], alpha=0.2, color=\"whitesmoke\")\n",
    "        else:\n",
    "            ax.axvspan(prices.index[i], prices.index[i + 1], alpha=0.2, color=\"deepskyblue\")\n",
    "    \n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.set_title(\"Market Regimes: White=Calm, Blue=Crisis\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def compute_regime_statistics(regimes: np.ndarray, calm_state: int) -> Dict[str, float]:\n",
    "    \"\"\"Compute summary statistics of regime frequencies.\"\"\"\n",
    "\n",
    "    crisis_state = 1 - calm_state\n",
    "    n_calm = int((regimes == calm_state).sum())\n",
    "    n_crisis = int((regimes == crisis_state).sum())\n",
    "    pct_calm = 100.0 * n_calm / len(regimes)\n",
    "    pct_crisis = 100.0 * n_crisis / len(regimes)\n",
    "\n",
    "    return {\n",
    "        \"n_calm_days\": n_calm,\n",
    "        \"n_crisis_days\": n_crisis,\n",
    "        \"pct_calm\": pct_calm,\n",
    "        \"pct_crisis\": pct_crisis,\n",
    "    }\n",
    "\n",
    "def fit_hmm(X_scaled: np.ndarray, n_components: int = 2) -> hmm.GaussianHMM:\n",
    "    \"\"\"Fit a Gaussian HMM to the scaled returns.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_scaled : np.ndarray\n",
    "        Scaled multivariate returns.\n",
    "    n_components : int\n",
    "        Number of hidden states (default: 2 for calm/crisis).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hmm.GaussianHMM\n",
    "        Fitted HMM model.\n",
    "    \"\"\"\n",
    "    model = hmm.GaussianHMM(n_components=n_components, random_state=RANDOM_SEED, n_iter=5000)\n",
    "    model.fit(X_scaled)\n",
    "    return model\n",
    "\n",
    "def run_regime_detection_pipeline() -> Tuple[Dict[str, float], np.ndarray, HMMResults, pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Run the full HMM-based regime detection workflow and return all key outputs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Dict[str, float], np.ndarray, HMMResults, pd.DataFrame, pd.Series]\n",
    "        Regime statistics, regime assignments, HMM results, cleaned log returns,\n",
    "        and aligned S&P 500 price series.\n",
    "    \"\"\"\n",
    "\n",
    "    # Data preparation\n",
    "    log_returns, sp500_prices = load_and_prepare_returns(COMBINED_PATH)\n",
    "\n",
    "    # Display which variables are being analyzed\n",
    "    print(\"=\" * 80)\n",
    "    print(\"MARKET VARIABLES USED FOR REGIME DETECTION (Multivariate Gaussian HMM):\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, col in enumerate(log_returns.columns, 1):\n",
    "        print(f\"{i}. {col}\")\n",
    "    print(f\"\\nTotal dimensions: {log_returns.shape[1]} variables Ã— {log_returns.shape[0]} observations\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    X_scaled, _, log_returns_clean = standardize_returns(log_returns)\n",
    "\n",
    "    # HMM fitting\n",
    "    model = fit_hmm(X_scaled, n_components=2)\n",
    "\n",
    "    # Regime identification\n",
    "    regimes, hmm_results = identify_regimes(model, X_scaled)\n",
    "\n",
    "    # Analyze feature contributions to regimes (use cleaned returns)\n",
    "    df_feature_analysis = analyze_hmm_features(log_returns_clean, hmm_results)\n",
    "    print(\"FEATURE ANALYSIS - Mean and Volatility per Regime:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df_feature_analysis.to_string(index=False))\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    # Align sp500_prices with cleaned returns\n",
    "    sp500_prices_clean = sp500_prices.loc[log_returns_clean.index]\n",
    "\n",
    "    # Visualization\n",
    "    FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = FIGURES_DIR / \"regime_visualization_sp500.png\"\n",
    "    visualize_regimes(\n",
    "        sp500_prices_clean,\n",
    "        regimes,\n",
    "        hmm_results.calm_state,\n",
    "        hmm_results.crisis_state,\n",
    "        plot_path,\n",
    "    )\n",
    "\n",
    "    # Save outputs (Gold layer)\n",
    "    DATA_GOLD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    regime_ts_path = DATA_GOLD_DIR / \"regime_timeseries.csv\"\n",
    "    save_regime_timeseries(log_returns_clean.index, regimes, sp500_prices_clean, hmm_results, regime_ts_path)\n",
    "\n",
    "    hmm_params_path = DATA_GOLD_DIR / \"hmm_parameters.txt\"\n",
    "    save_hmm_parameters(hmm_results, hmm_params_path)\n",
    "\n",
    "    # Statistics\n",
    "    stats = compute_regime_statistics(regimes, hmm_results.calm_state)\n",
    "    return stats, regimes, hmm_results, log_returns_clean, sp500_prices_clean\n",
    "\n",
    "def save_regime_timeseries(\n",
    "    dates: pd.DatetimeIndex,\n",
    "    regimes: np.ndarray,\n",
    "    sp500_prices: pd.Series,\n",
    "    hmm_results: HMMResults,\n",
    "    output_path: Path\n",
    ") -> None:\n",
    "    \"\"\"Save regime time series to CSV.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dates : pd.DatetimeIndex\n",
    "        Index dates.\n",
    "    regimes : np.ndarray\n",
    "        Regime assignments.\n",
    "    sp500_prices : pd.Series\n",
    "        S&P 500 prices.\n",
    "    hmm_results : HMMResults\n",
    "        HMM results container.\n",
    "    output_path : Path\n",
    "        Path to save CSV.\n",
    "    \"\"\"\n",
    "    df_regimes = pd.DataFrame({\n",
    "        \"date\": dates,\n",
    "        \"regime\": regimes,\n",
    "        \"regime_label\": [\"CALM\" if r == hmm_results.calm_state else \"CRISIS\" for r in regimes],\n",
    "        \"sp500_price\": sp500_prices.values\n",
    "    })\n",
    "    df_regimes.set_index(\"date\", inplace=True)\n",
    "    df_regimes.to_csv(output_path)\n",
    "\n",
    "# =============================================================================\n",
    "# FASE 3 - Cuando la DiversificaciÃ³n Falla (CÃ³pulas)\n",
    "# =============================================================================\n",
    "\n",
    "def compute_correlation_by_regime(\n",
    "    asset_returns_by_regime: Dict[str, pd.DataFrame]\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Compute Pearson correlation matrices for each regime (CALM/CRISIS).\"\"\"\n",
    "    correlation_matrices: Dict[str, pd.DataFrame] = {}\n",
    "    for regime_name, returns_df in asset_returns_by_regime.items():\n",
    "        correlation_matrices[regime_name] = returns_df.dropna(axis=1, how=\"all\").corr()\n",
    "    return correlation_matrices\n",
    "\n",
    "def calibrate_gaussian_copulas(\n",
    "    asset_returns_by_regime: Dict[str, pd.DataFrame]\n",
    ") -> Dict[str, RegimeCopula]:\n",
    "    \"\"\"Calibrate Gaussian copulas for each regime using pseudo-observations.\"\"\"\n",
    "    copulas: Dict[str, RegimeCopula] = {}\n",
    "\n",
    "    for regime_name, returns_df in asset_returns_by_regime.items():\n",
    "        clean = returns_df.dropna()\n",
    "        if clean.empty:\n",
    "            continue\n",
    "\n",
    "        assets = list(clean.columns)\n",
    "\n",
    "        # Pseudo-observations U in (0,1) via ranks\n",
    "        ranks = clean.rank(axis=0, method=\"average\")\n",
    "        u = (ranks - 0.5) / len(clean)\n",
    "\n",
    "        # Map to standard normal via inverse CDF\n",
    "        z = sp_stats.norm.ppf(u)\n",
    "        corr = pd.DataFrame(np.corrcoef(z.T), index=assets, columns=assets)\n",
    "\n",
    "        copulas[regime_name] = RegimeCopula(\n",
    "            regime_name=regime_name,\n",
    "            assets=assets,\n",
    "            correlation=corr,\n",
    "        )\n",
    "\n",
    "    return copulas\n",
    "\n",
    "def plot_correlation_heatmaps(\n",
    "    correlation_matrices: Dict[str, pd.DataFrame],\n",
    "    output_dir: Path = FIGURES_DIR,\n",
    ") -> None:\n",
    "    \"\"\"Save correlation heatmaps for each regime to the figures directory.\"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for regime_name, corr in correlation_matrices.items():\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr, cmap=\"coolwarm\", center=0, annot=False)\n",
    "        plt.title(f\"Correlation Matrix - {regime_name} Regime\")\n",
    "        plt.tight_layout()\n",
    "        fig_path = output_dir / f\"correlation_matrix_{regime_name.lower()}.png\"\n",
    "        plt.savefig(fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "def run_phase3_copula_analysis(\n",
    "    portfolio: Portfolio,\n",
    "    regimes: np.ndarray,\n",
    "    log_returns_clean: pd.DataFrame,\n",
    "    hmm_results: HMMResults,\n",
    ") -> Tuple[Dict[str, pd.DataFrame], Dict[str, RegimeCopula]]:\n",
    "    \"\"\"Phase 3: correlations and copulas by regime.\"\"\"\n",
    "\n",
    "    # Reuse separation utility (already defined in Phase 1 code)\n",
    "    _, asset_returns_by_regime = separate_data_by_regime(\n",
    "        portfolio=portfolio,\n",
    "        regimes=regimes,\n",
    "        log_returns_clean=log_returns_clean,\n",
    "        hmm_results=hmm_results,\n",
    "    )\n",
    "\n",
    "    corr_by_regime = compute_correlation_by_regime(asset_returns_by_regime)\n",
    "    copulas_by_regime = calibrate_gaussian_copulas(asset_returns_by_regime)\n",
    "\n",
    "    # Save visual evidence for the report\n",
    "    plot_correlation_heatmaps(corr_by_regime, FIGURES_DIR)\n",
    "\n",
    "    # Simple numeric evidence of â€œcorrelations go to 1â€ in crisis\n",
    "    if \"CALM\" in corr_by_regime and \"CRISIS\" in corr_by_regime:\n",
    "        common_assets = corr_by_regime[\"CALM\"].columns.intersection(\n",
    "            corr_by_regime[\"CRISIS\"].columns\n",
    "        )\n",
    "        diff = (\n",
    "            corr_by_regime[\"CRISIS\"].loc[common_assets, common_assets]\n",
    "            - corr_by_regime[\"CALM\"].loc[common_assets, common_assets]\n",
    "        )\n",
    "        off_diag = diff.values[~np.eye(len(common_assets), dtype=bool)]\n",
    "        print(\"Correlation change (CRISIS - CALM):\")\n",
    "        print(f\"  Mean off-diagonal change: {off_diag.mean():.3f}\")\n",
    "        print(f\"  Max off-diagonal increase: {off_diag.max():.3f}\")\n",
    "\n",
    "    return corr_by_regime, copulas_by_regime\n",
    "\n",
    "# =============================================================================\n",
    "# FASE 4 - El Motor de SimulaciÃ³n\n",
    "# =============================================================================\n",
    "\n",
    "def compute_portfolio_wealth(\n",
    "    returns: np.ndarray,\n",
    "    weights: np.ndarray,\n",
    "    initial_wealth: float = 1.0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute wealth paths from multi-asset returns and static weights.\"\"\"\n",
    "    n_paths, n_steps, _ = returns.shape\n",
    "    wealth = np.full((n_paths, n_steps + 1), initial_wealth, dtype=float)\n",
    "\n",
    "    for p in range(n_paths):\n",
    "        for t in range(n_steps):\n",
    "            portfolio_ret = np.dot(returns[p, t, :], weights)\n",
    "            wealth[p, t + 1] = wealth[p, t] * (1.0 + portfolio_ret)\n",
    "\n",
    "    return wealth\n",
    "\n",
    "def compute_risk_metrics_from_returns(returns: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"Compute basic risk metrics from a 1D array of portfolio returns.\"\"\"\n",
    "    series = pd.Series(returns)\n",
    "    mu = float(series.mean())\n",
    "    sigma = float(series.std())\n",
    "    ann_mu = mu * 252\n",
    "    ann_vol = sigma * np.sqrt(252)\n",
    "\n",
    "    wealth = (1 + series).cumprod()\n",
    "    peak = wealth.cummax()\n",
    "    drawdown = (wealth - peak) / peak\n",
    "    max_dd = float(drawdown.min())\n",
    "\n",
    "    var_99 = float(series.quantile(0.01))\n",
    "    cvar_99 = float(series[series <= var_99].mean())\n",
    "\n",
    "    return {\n",
    "        \"Mean Return (ann)\": ann_mu,\n",
    "        \"Volatility (ann)\": ann_vol,\n",
    "        \"Max Drawdown\": max_dd,\n",
    "        \"VaR 99%\": var_99,\n",
    "        \"CVaR 99%\": cvar_99,\n",
    "    }\n",
    "\n",
    "def plot_phase4_wealth_and_returns(\n",
    "    real_returns: pd.Series,\n",
    "    simulated_daily: np.ndarray,\n",
    "    wealth_paths: np.ndarray,\n",
    "    n_days: int,\n",
    "    output_dir: Path = FIGURES_DIR,\n",
    ") -> None:\n",
    "    \"\"\"Create Phase 4 diagnostic plots (wealth fan chart and return distributions).\n",
    "\n",
    "    - Wealth fan chart: real wealth vs bandas p5â€“p50â€“p95 simuladas.\n",
    "    - Histogram de retornos diarios (real vs simulado).\n",
    "    \"\"\"\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Align last n_days of real returns\n",
    "    real_tail = real_returns.iloc[-n_days:]\n",
    "    wealth_real = (1.0 + real_tail).cumprod()\n",
    "\n",
    "    # Wealth fan chart\n",
    "    quantiles = np.quantile(wealth_paths, [0.05, 0.5, 0.95], axis=0)\n",
    "    t_grid = np.arange(wealth_paths.shape[1])\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.fill_between(t_grid, quantiles[0], quantiles[2], color=\"lightblue\", alpha=0.4, label=\"p5â€“p95 simulado\")\n",
    "    plt.plot(t_grid, quantiles[1], color=\"blue\", linewidth=1.5, label=\"p50 simulado\")\n",
    "    plt.plot(np.arange(len(wealth_real)), wealth_real.values, color=\"black\", linewidth=1.5, label=\"Wealth real\")\n",
    "    plt.xlabel(\"DÃ­as\")\n",
    "    plt.ylabel(\"Ãndice de riqueza\")\n",
    "    plt.title(\"Fase 4 â€“ Wealth real vs abanico simulado\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / \"phase4_wealth_fan.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # DistribuciÃ³n de retornos diarios\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.hist(real_returns.values, bins=50, alpha=0.6, label=\"Real\", density=True)\n",
    "    plt.hist(simulated_daily, bins=50, alpha=0.4, label=\"Simulado\", density=True)\n",
    "    plt.xlabel(\"Retorno diario\")\n",
    "    plt.ylabel(\"Densidad\")\n",
    "    plt.title(\"Fase 4 â€“ DistribuciÃ³n de retornos diarios (real vs simulado)\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / \"phase4_returns_hist.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def summarize_regime_paths(regimes: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"Summarize regime frequencies, mean duration and number of switches.\"\"\"\n",
    "    flat = regimes.flatten()\n",
    "    n_obs = len(flat)\n",
    "\n",
    "    pct_state0 = 100.0 * np.mean(flat == 0)\n",
    "    pct_state1 = 100.0 * np.mean(flat == 1)\n",
    "\n",
    "    switches = np.sum(flat[1:] != flat[:-1])\n",
    "\n",
    "    durations = []\n",
    "    current = flat[0]\n",
    "    length = 1\n",
    "    for s in flat[1:]:\n",
    "        if s == current:\n",
    "            length += 1\n",
    "        else:\n",
    "            durations.append((current, length))\n",
    "            current = s\n",
    "            length = 1\n",
    "    durations.append((current, length))\n",
    "\n",
    "    mean_dur_0 = np.mean([d for state, d in durations if state == 0])\n",
    "    mean_dur_1 = np.mean([d for state, d in durations if state == 1])\n",
    "\n",
    "    return {\n",
    "        \"%_state0\": pct_state0,\n",
    "        \"%_state1\": pct_state1,\n",
    "        \"mean_duration_state0\": float(mean_dur_0),\n",
    "        \"mean_duration_state1\": float(mean_dur_1),\n",
    "        \"n_switches\": float(switches),\n",
    "        \"n_obs\": float(n_obs),\n",
    "    }\n",
    "\n",
    "def run_phase4_simulation(\n",
    "    portfolio: Portfolio,\n",
    "    hmm_results: HMMResults,\n",
    "    df_stats: pd.DataFrame,\n",
    "    corr_by_regime: Dict[str, pd.DataFrame],\n",
    "    copulas_by_regime: Dict[str, RegimeCopula],\n",
    "    n_paths: int = 10_000,\n",
    "    n_days: int = 126,\n",
    ") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"Phase 4: Monte Carlo simulation + validations.\"\"\"\n",
    "\n",
    "    regime_marginals: Dict[str, pd.DataFrame] = {}\n",
    "    for regime_name in [\"CALM\", \"CRISIS\"]:\n",
    "        regime_marginals[regime_name] = df_stats[df_stats[\"Regime\"] == regime_name].copy()\n",
    "\n",
    "    assets = [\n",
    "        a for a in portfolio.prices.columns\n",
    "        if a in regime_marginals[\"CALM\"][\"Asset\"].values\n",
    "    ]\n",
    "    weights = np.repeat(1.0 / len(assets), len(assets))\n",
    "\n",
    "    simulator = RegimeMonteCarloSimulator(\n",
    "        transition_matrix=hmm_results.transition_matrix,\n",
    "        assets=assets,\n",
    "        regime_marginals=regime_marginals,\n",
    "        regime_copulas=copulas_by_regime,\n",
    "    )\n",
    "\n",
    "    simulated_returns, simulated_regimes = simulator.simulate_returns(\n",
    "        n_paths=n_paths,\n",
    "        n_steps=n_days,\n",
    "        initial_state=hmm_results.calm_state,\n",
    "    )\n",
    "\n",
    "    # Real equal-weight portfolio on same assets\n",
    "    real_returns = portfolio.returns[assets].dropna().mean(axis=1)\n",
    "\n",
    "    wealth_paths = compute_portfolio_wealth(simulated_returns, weights)\n",
    "    simulated_portfolio_returns = wealth_paths[:, 1:] / wealth_paths[:, :-1] - 1.0\n",
    "    simulated_daily = simulated_portfolio_returns.reshape(-1)\n",
    "\n",
    "    # Generate Phase 4 diagnostic plots\n",
    "    plot_phase4_wealth_and_returns(\n",
    "        real_returns=real_returns,\n",
    "        simulated_daily=simulated_daily,\n",
    "        wealth_paths=wealth_paths,\n",
    "        n_days=n_days,\n",
    "        output_dir=FIGURES_DIR,\n",
    "    )\n",
    "\n",
    "    real_metrics = compute_risk_metrics_from_returns(real_returns.values)\n",
    "    simulated_metrics = compute_risk_metrics_from_returns(simulated_daily)\n",
    "    sim_regime_stats = summarize_regime_paths(simulated_regimes)\n",
    "\n",
    "    return {\n",
    "        \"real_portfolio\": real_metrics,\n",
    "        \"simulated_portfolio\": simulated_metrics,\n",
    "        \"simulated_regimes\": sim_regime_stats,\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# FASE 5 - Escenarios de EstrÃ©s\n",
    "# =============================================================================\n",
    "def apply_scenario_to_marginals(\n",
    "    base_marginals: Dict[str, pd.DataFrame],\n",
    "    scenario: StressScenario,\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Return copy of marginal stats with scenario-specific volatility shocks.\"\"\"\n",
    "    marginals = {}\n",
    "    for regime_name, df_regime in base_marginals.items():\n",
    "        df_new = df_regime.copy()\n",
    "        for asset, mult in scenario.volatility_multipliers.items():\n",
    "            mask = df_new[\"Asset\"] == asset\n",
    "            df_new.loc[mask, \"Volatility\"] *= mult\n",
    "        marginals[regime_name] = df_new\n",
    "    return marginals\n",
    "\n",
    "def run_stress_scenario(\n",
    "    portfolio: Portfolio,\n",
    "    hmm_results: HMMResults,\n",
    "    df_stats: pd.DataFrame,\n",
    "    copulas_by_regime: Dict[str, RegimeCopula],\n",
    "    scenario: StressScenario,\n",
    "    n_paths: int = 10_000,\n",
    "    n_days: int = 126,\n",
    ") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"Run Monte Carlo simulation under a given stress scenario.\"\"\"\n",
    "    base_marginals: Dict[str, pd.DataFrame] = {}\n",
    "    for regime_name in [\"CALM\", \"CRISIS\"]:\n",
    "        base_marginals[regime_name] = df_stats[df_stats[\"Regime\"] == regime_name].copy()\n",
    "\n",
    "    stressed_marginals = apply_scenario_to_marginals(base_marginals, scenario)\n",
    "\n",
    "    assets = [\n",
    "        a for a in portfolio.prices.columns\n",
    "        if a in stressed_marginals[\"CALM\"][\"Asset\"].values\n",
    "    ]\n",
    "    weights = np.repeat(1.0 / len(assets), len(assets))\n",
    "\n",
    "    simulator = RegimeMonteCarloSimulator(\n",
    "        transition_matrix=scenario.transition_matrix,\n",
    "        assets=assets,\n",
    "        regime_marginals=stressed_marginals,\n",
    "        regime_copulas=copulas_by_regime,\n",
    "    )\n",
    "\n",
    "    simulated_returns, simulated_regimes = simulator.simulate_returns(\n",
    "        n_paths=n_paths,\n",
    "        n_steps=n_days,\n",
    "        initial_state=hmm_results.calm_state,\n",
    "    )\n",
    "\n",
    "    wealth_paths = compute_portfolio_wealth(simulated_returns, weights)\n",
    "    simulated_portfolio_returns = wealth_paths[:, 1:] / wealth_paths[:, :-1] - 1.0\n",
    "    simulated_daily = simulated_portfolio_returns.reshape(-1)\n",
    "\n",
    "    portfolio_metrics = compute_risk_metrics_from_returns(simulated_daily)\n",
    "    regime_stats = summarize_regime_paths(simulated_regimes)\n",
    "\n",
    "    return {\n",
    "        \"scenario\": {\n",
    "            \"name\": scenario.name,\n",
    "            \"description\": scenario.description,\n",
    "        },\n",
    "        \"portfolio_metrics\": portfolio_metrics,\n",
    "        \"regime_stats\": regime_stats,\n",
    "    }\n",
    "\n",
    "def plot_phase5_scenario_risk(\n",
    "    stress_results: Dict[str, Dict[str, Dict[str, float]]],\n",
    "    output_dir: Path = FIGURES_DIR,\n",
    ") -> None:\n",
    "    \"\"\"Create a bar chart comparing VaR/CVaR 99% across stress scenarios (Phase 5).\"\"\"\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    scenario_names: list[str] = []\n",
    "    var_values: list[float] = []\n",
    "    cvar_values: list[float] = []\n",
    "\n",
    "    for name, res in stress_results.items():\n",
    "        metrics = res.get(\"portfolio_metrics\", {})\n",
    "        scenario_names.append(name)\n",
    "        var_values.append(metrics.get(\"VaR 99%\", np.nan))\n",
    "        cvar_values.append(metrics.get(\"CVaR 99%\", np.nan))\n",
    "\n",
    "    x = np.arange(len(scenario_names))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.bar(x - width / 2, var_values, width, label=\"VaR 99%\")\n",
    "    plt.bar(x + width / 2, cvar_values, width, label=\"CVaR 99%\")\n",
    "    plt.xticks(x, scenario_names, rotation=15)\n",
    "    plt.ylabel(\"Retorno (pÃ©rdida negativa)\")\n",
    "    plt.title(\"Fase 5 â€“ ComparaciÃ³n de VaR/CVaR 99% por escenario de estrÃ©s\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / \"phase5_scenario_risk.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def build_default_stress_scenarios(hmm_results: HMMResults) -> List[StressScenario]:\n",
    "    \"\"\"Define three illustrative stress scenarios for Phase 5.\"\"\"\n",
    "    base_T = hmm_results.transition_matrix.copy()\n",
    "\n",
    "    # Scenario 1: Stagflation 2022 â€“ more time in crisis, higher rate volatility\n",
    "    T_stagflation = base_T.copy()\n",
    "    T_stagflation[hmm_results.calm_state, hmm_results.calm_state] = 0.90\n",
    "    T_stagflation[hmm_results.calm_state, hmm_results.crisis_state] = 0.10\n",
    "\n",
    "    stagflation = StressScenario(\n",
    "        name=\"Stagflation 2022\",\n",
    "        description=\"High inflation, rising rates, persistent risk-off episodes.\",\n",
    "        transition_matrix=T_stagflation,\n",
    "        volatility_multipliers={\"GS10\": 1.5, \"GS2\": 1.5, \"GLD\": 1.2},\n",
    "    )\n",
    "\n",
    "    # Scenario 2: Credit Crisis 2008 â€“ strong equity/credit shock\n",
    "    T_credit = base_T.copy()\n",
    "    T_credit[hmm_results.calm_state, hmm_results.calm_state] = 0.80\n",
    "    T_credit[hmm_results.calm_state, hmm_results.crisis_state] = 0.20\n",
    "\n",
    "    credit_crisis = StressScenario(\n",
    "        name=\"Credit Crisis 2008\",\n",
    "        description=\"Systemic credit stress, widening spreads, sharp equity drawdowns.\",\n",
    "        transition_matrix=T_credit,\n",
    "        volatility_multipliers={\"HYG\": 2.0, \"BAC\": 1.8, \"JPM\": 1.8},\n",
    "    )\n",
    "\n",
    "    # Scenario 3: Custom mixed macro + credit shock\n",
    "    T_custom = base_T.copy()\n",
    "    T_custom[hmm_results.calm_state, hmm_results.calm_state] = 0.85\n",
    "    T_custom[hmm_results.calm_state, hmm_results.crisis_state] = 0.15\n",
    "\n",
    "    custom = StressScenario(\n",
    "        name=\"Mixed Shock\",\n",
    "        description=\"Combined macro and credit shock with moderate persistence.\",\n",
    "        transition_matrix=T_custom,\n",
    "        volatility_multipliers={\"HYG\": 1.5, \"GLD\": 1.3, \"GS10\": 1.4},\n",
    "    )\n",
    "\n",
    "    return [stagflation, credit_crisis, custom]\n",
    "\n",
    "def run_stress_scenario(\n",
    "    portfolio: Portfolio,\n",
    "    hmm_results: HMMResults,\n",
    "    df_stats: pd.DataFrame,\n",
    "    copulas_by_regime: Dict[str, RegimeCopula],\n",
    "    scenario: StressScenario,\n",
    "    n_paths: int = 10_000,\n",
    "    n_days: int = 126,\n",
    ") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"Run Monte Carlo simulation under a given stress scenario.\n",
    "\n",
    "    This version extends the base implementation by:\n",
    "    - computing risk metrics for the *real* equal-weight portfolio on the same assets,\n",
    "    - generating wealth and return-distribution plots for each scenario (Phase 5).\n",
    "    \"\"\"\n",
    "\n",
    "    # Base marginal statistics by regime (CALM / CRISIS)\n",
    "    base_marginals: Dict[str, pd.DataFrame] = {}\n",
    "    for regime_name in [\"CALM\", \"CRISIS\"]:\n",
    "        base_marginals[regime_name] = df_stats[df_stats[\"Regime\"] == regime_name].copy()\n",
    "\n",
    "    stressed_marginals = apply_scenario_to_marginals(base_marginals, scenario)\n",
    "\n",
    "    # Asset universe used in the simulation (intersection with marginal stats)\n",
    "    assets = [\n",
    "        a for a in portfolio.prices.columns\n",
    "        if a in stressed_marginals[\"CALM\"][\"Asset\"].values\n",
    "    ]\n",
    "    weights = np.repeat(1.0 / len(assets), len(assets))\n",
    "\n",
    "    # Real equal-weight portfolio returns on the same asset set\n",
    "    real_returns = portfolio.returns[assets].dropna().mean(axis=1)\n",
    "\n",
    "    # Simulated paths under the stress scenario\n",
    "    simulator = RegimeMonteCarloSimulator(\n",
    "        transition_matrix=scenario.transition_matrix,\n",
    "        assets=assets,\n",
    "        regime_marginals=stressed_marginals,\n",
    "        regime_copulas=copulas_by_regime,\n",
    "    )\n",
    "\n",
    "    simulated_returns, simulated_regimes = simulator.simulate_returns(\n",
    "        n_paths=n_paths,\n",
    "        n_steps=n_days,\n",
    "        initial_state=hmm_results.calm_state,\n",
    "    )\n",
    "\n",
    "    wealth_paths = compute_portfolio_wealth(simulated_returns, weights)\n",
    "    simulated_portfolio_returns = wealth_paths[:, 1:] / wealth_paths[:, :-1] - 1.0\n",
    "    simulated_daily = simulated_portfolio_returns.reshape(-1)\n",
    "\n",
    "    # Risk metrics (real vs stressed)\n",
    "    real_metrics = compute_risk_metrics_from_returns(real_returns.values)\n",
    "    portfolio_metrics = compute_risk_metrics_from_returns(simulated_daily)\n",
    "    regime_stats = summarize_regime_paths(simulated_regimes)\n",
    "\n",
    "    # Phase 5 diagnostic plots for this specific scenario\n",
    "    plot_phase5_scenario_wealth_and_returns(\n",
    "        scenario_name=scenario.name,\n",
    "        real_returns=real_returns,\n",
    "        simulated_daily=simulated_daily,\n",
    "        wealth_paths=wealth_paths,\n",
    "        n_days=n_days,\n",
    "        output_dir=FIGURES_DIR,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"scenario\": {\n",
    "            \"name\": scenario.name,\n",
    "            \"description\": scenario.description,\n",
    "        },\n",
    "        \"real_portfolio\": real_metrics,\n",
    "        \"portfolio_metrics\": portfolio_metrics,\n",
    "        \"regime_stats\": regime_stats,\n",
    "    }\n",
    "\n",
    "def plot_phase5_scenario_wealth_and_returns(\n",
    "    scenario_name: str,\n",
    "    real_returns: pd.Series,\n",
    "    simulated_daily: np.ndarray,\n",
    "    wealth_paths: np.ndarray,\n",
    "    n_days: int,\n",
    "    output_dir: Path = FIGURES_DIR,\n",
    ") -> None:\n",
    "    \"\"\"Create Phase 5 diagnostic plots for a stress scenario (wealth fan chart and return distributions).\"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Align last n_days of real returns\n",
    "    real_tail = real_returns.iloc[-n_days:]\n",
    "    wealth_real = (1.0 + real_tail).cumprod()\n",
    "\n",
    "    # Wealth fan chart\n",
    "    quantiles = np.quantile(wealth_paths, [0.05, 0.5, 0.95], axis=0)\n",
    "    t_grid = np.arange(wealth_paths.shape[1])\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.fill_between(t_grid, quantiles[0], quantiles[2], color=\"lightcoral\", alpha=0.4, label=\"p5â€“p95 simulado (stress)\")\n",
    "    plt.plot(t_grid, quantiles[1], color=\"red\", linewidth=1.5, label=\"p50 simulado (stress)\")\n",
    "    plt.plot(np.arange(len(wealth_real)), wealth_real.values, color=\"black\", linewidth=1.5, label=\"Wealth real\")\n",
    "    plt.xlabel(\"DÃ­as\")\n",
    "    plt.ylabel(\"Ãndice de riqueza\")\n",
    "    plt.title(f\"Fase 5 â€“ {scenario_name}: Wealth real vs abanico simulado\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    safe_name = scenario_name.lower().replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    plt.savefig(output_dir / f\"phase5_{safe_name}_wealth_fan.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # DistribuciÃ³n de retornos diarios\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.hist(real_returns.values, bins=50, alpha=0.6, label=\"Real\", density=True, color=\"black\")\n",
    "    plt.hist(simulated_daily, bins=50, alpha=0.4, label=\"Simulado (stress)\", density=True, color=\"red\")\n",
    "    plt.xlabel(\"Retorno diario\")\n",
    "    plt.ylabel(\"Densidad\")\n",
    "    plt.title(f\"Fase 5 â€“ {scenario_name}: DistribuciÃ³n de retornos diarios (real vs simulado)\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f\"phase5_{safe_name}_returns_hist.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c4b9a8",
   "metadata": {},
   "source": [
    "### Report ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown_to_pdf(markdown_path: Path, pdf_path: Path) -> None:\n",
    "    \"\"\"Convert markdown file to PDF using markdown + weasyprint.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    markdown_path : Path\n",
    "        Path to input markdown file.\n",
    "    pdf_path : Path\n",
    "        Path to output PDF file.\n",
    "    \"\"\"\n",
    "    if not PDF_AVAILABLE:\n",
    "        print(f\"PDF generation skipped: markdown/weasyprint not available.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Read markdown\n",
    "        with open(markdown_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            md_content = f.read()\n",
    "        \n",
    "        # Convert markdown to HTML\n",
    "        html_content = markdown.markdown(\n",
    "            md_content,\n",
    "            extensions=['extra', 'tables', 'codehilite'],\n",
    "            extension_configs={\n",
    "                'codehilite': {\n",
    "                    'css_class': 'highlight'\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Add basic CSS styling for PDF\n",
    "        html_with_style = f\"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <meta charset=\"utf-8\">\n",
    "            <style>\n",
    "                @page {{\n",
    "                    size: A4;\n",
    "                    margin: 1cm;\n",
    "                }}\n",
    "                body {{\n",
    "                    font-family: 'Arial', sans-serif;\n",
    "                    font-size: 10pt;\n",
    "                    line-height: 1.6;\n",
    "                    color: #333;\n",
    "                }}\n",
    "                h1 {{\n",
    "                    font-size: 16pt;\n",
    "                    color: #1a1a1a;\n",
    "                    border-bottom: 2px solid #333;\n",
    "                }}\n",
    "                h2 {{\n",
    "                    font-size: 14pt;\n",
    "                    color: #2a2a2a;\n",
    "                    margin-top: 0.3cm;\n",
    "                    margin-bottom: 0.4cm;\n",
    "                }}\n",
    "                h3 {{\n",
    "                    font-size: 12pt;\n",
    "                    color: #3a3a3a;\n",
    "                    margin-top: 0.3cm;\n",
    "                    margin-bottom: 0.3cm;\n",
    "                }}\n",
    "                table {{\n",
    "                    border-collapse: collapse;\n",
    "                    width: 100%;\n",
    "                    margin: 0.1cm 0;\n",
    "                    font-size: 9pt;\n",
    "                }}\n",
    "                th, td {{\n",
    "                    border: 1px solid #ddd;\n",
    "                    padding: 1px;\n",
    "                    text-align: left;\n",
    "                }}\n",
    "                th {{\n",
    "                    background-color: #f2f2f2;\n",
    "                    font-weight: bold;\n",
    "                }}\n",
    "                code {{\n",
    "                    background-color: #f4f4f4;\n",
    "                    padding: 2px 4px;\n",
    "                    border-radius: 3px;\n",
    "                    font-family: 'Courier New', monospace;\n",
    "                    font-size: 9pt;\n",
    "                }}\n",
    "                pre {{\n",
    "                    background-color: #f4f4f4;\n",
    "                    padding: 0.5cm;\n",
    "                    border-radius: 5px;\n",
    "                    overflow-x: auto;\n",
    "                    font-size: 8pt;\n",
    "                }}\n",
    "                img {{\n",
    "                    max-width: 100%;\n",
    "                    height: auto;\n",
    "                    page-break-inside: avoid;\n",
    "                }}\n",
    "                p {{\n",
    "                    margin: 0.3cm 0;\n",
    "                }}\n",
    "                ul, ol {{\n",
    "                    margin: 0.3cm 0;\n",
    "                    padding-left: 1cm;\n",
    "                }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            {html_content}\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert HTML to PDF\n",
    "        pdf_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        HTML(string=html_with_style, base_url=str(markdown_path.parent)).write_pdf(pdf_path)\n",
    "        print(f\"âœ“ PDF generado: {pdf_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generando PDF: {e}\")\n",
    "        print(\"AsegÃºrate de tener instalado: pip install markdown weasyprint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4922ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_executive_report(\n",
    "    output_path: Path,\n",
    "    regime_stats: Dict[str, float],\n",
    "    df_stats: pd.DataFrame,\n",
    "    df_key_assets: pd.DataFrame,\n",
    "    df_vol_comparison: pd.DataFrame,\n",
    "    real_regime_summary: Dict[str, float] | None = None,\n",
    "    phase4_results: Dict[str, Dict[str, float]] | None = None,\n",
    "    stress_results: Dict[str, Dict[str, Dict[str, float]]] | None = None,\n",
    ") -> str:\n",
    "    \"\"\"Generate a concise executive report (max 3 pages) for Risk Committee.\n",
    "    \n",
    "    Focus: Economic interpretation, regime differentiation, stress scenario insights.\n",
    "    \"\"\"\n",
    "    \n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    report: list[str] = []\n",
    "    \n",
    "    # ============================================================================\n",
    "    # HEADER\n",
    "    # ============================================================================\n",
    "    report.append(\"# Escenarios de EstrÃ©s y Cambios de RÃ©gimen de Mercado\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"**Alumno:** Piettro Rodrigues\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"---\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    # ============================================================================\n",
    "    # RESUMEN EJECUTIVO\n",
    "    # ============================================================================\n",
    "    report.append(\"\")\n",
    "    report.append(\n",
    "        \"Este informe presenta un motor de stress testing basado en modelos Hidden Markov \"\n",
    "        \"(HMM) que identifica dos regÃ­menes de mercado: **CALMA** y **CRISIS**. El modelo \"\n",
    "        \"captura el riesgo de cola y la desapariciÃ³n de la diversificaciÃ³n en perÃ­odos de estrÃ©s, \"\n",
    "        \"permitiendo cuantificar pÃ©rdidas extremas mediante VaR 99% y Expected Shortfall (CVaR).\"\n",
    "    )\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # Â¿QUÃ‰ DIFERENCIA CALMA DE CRISIS? (RESPUESTA EXPLÃCITA)\n",
    "    # ============================================================================\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # Extraer datos clave para interpretaciÃ³n\n",
    "    hyg_calm = df_key_assets[(df_key_assets[\"Asset\"] == \"HYG\") & (df_key_assets[\"Regime\"] == \"CALM\")]\n",
    "    hyg_crisis = df_key_assets[(df_key_assets[\"Asset\"] == \"HYG\") & (df_key_assets[\"Regime\"] == \"CRISIS\")]\n",
    "    \n",
    "    hyg_vol_increase = ((hyg_crisis[\"Volatility (%)\"].iloc[0] / hyg_calm[\"Volatility (%)\"].iloc[0] - 1) * 100) if not hyg_calm.empty and not hyg_crisis.empty else 0\n",
    "    \n",
    "    '''\n",
    "    report.append(\"** Evidencia Cuantitativa**\")\n",
    "    report.append(\"\")\n",
    "    report.append(f\"- **Frecuencia:** {regime_stats['pct_calm']:.1f}% dÃ­as en CALMA vs {regime_stats['pct_crisis']:.1f}% en CRISIS\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"**AmplificaciÃ³n de Volatilidad en CRISIS (top 5 activos):**\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # Top 5 por ratio de volatilidad\n",
    "    top5_vol = df_vol_comparison.nlargest(5, \"Ratio (Crisis/Calm)\")\n",
    "    for _, row in top5_vol.iterrows():\n",
    "        report.append(f\"- **{row['Asset']}**: {row['Ratio (Crisis/Calm)']:.1f}x ({row['% Change']:.0f}% aumento)\")\n",
    "    report.append(\"\")\n",
    "    '''\n",
    "\n",
    "    report.append(\"### InterpretaciÃ³n EconÃ³mica\")\n",
    "    report.append(\"\")\n",
    "    report.append(\n",
    "        \"La frecuencia observada es de 59.2% de los dÃ­as en rÃ©gimen de **CALMA** frente a 40.8% en **CRISIS**. \"\n",
    "        \"En el rÃ©gimen de **CRISIS** se observa una clara amplificaciÃ³n de la volatilidad, especialmente en los siguientes activos: \"\n",
    "        \"GS2 (3.9x, 287% de aumento), GS10 (3.1x, 213% de aumento), HYG (2.8x, 181% de aumento), BAC (2.5x, 150% de aumento) y JPM \"\n",
    "        \"(2.4x, 144% de aumento). En tÃ©rminos de interpretaciÃ³n econÃ³mica, el rÃ©gimen de **CALMA** se caracteriza por volatilidades bajas\"\n",
    "        \" y estables, correlaciones moderadas que permiten una diversificaciÃ³n efectiva y retornos positivos en promedio; mientras que el \"\n",
    "        \"rÃ©gimen de **CRISIS** se distingue por volatilidades que se multiplican entre 2 y 4 veces â€”especialmente en tipos de interÃ©s y \"\n",
    "        \"crÃ©ditoâ€”, correlaciones que convergen hacia 1 eliminando los beneficios de diversificaciÃ³n, y retornos promedio negativos \"\n",
    "        \"acompaÃ±ados de colas mÃ¡s pesadas.\"\n",
    "    )\n",
    "    report.append(\"\")\n",
    "    report.append(\n",
    "        f\"**Ejemplo crÃ­tico - High Yield (HYG):** La volatilidad aumenta {hyg_vol_increase:.0f}% \"\n",
    "        \"en crisis, reflejando widening de spreads de crÃ©dito y aversiÃ³n al riesgo. \"\n",
    "        \"**Oro (GLD):** Mantiene volatilidad relativamente estable (+30%), pero no actÃºa como \"\n",
    "        \"refugio esperado (retornos similares en ambos regÃ­menes), sugiriendo posible \"\n",
    "        \"liquidaciÃ³n forzada en crisis extremas.\"\n",
    "    )\n",
    "    report.append(\"\")\n",
    "    report.append(\"![RegÃ­menes de Mercado](../figures/regime_visualization_sp500.png)\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # FASE 4: EL MOTOR DE SIMULACIÃ“N\n",
    "    # ============================================================================\n",
    "    report.append(\"---\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"## El Motor de SimulaciÃ³n\")\n",
    "    report.append(\"\")\n",
    "    report.append(\n",
    "        \"**Objetivo:** Crear el futuro sintÃ©tico mediante simulaciÃ³n de Monte Carlo \"\n",
    "        \"(10.000 trayectorias, 6 meses) que genere retornos multiactivo coherentes con los \"\n",
    "        \"regÃ­menes estimados y con la estructura de dependencia en colas.\"\n",
    "    )\n",
    "    report.append(\"\")\n",
    "    report.append(\"**Tarea tÃ©cnica (simulador):**\")\n",
    "    report.append(\"\")\n",
    "    report.append(\n",
    "        \"Para cada trayectoria y cada dÃ­a: (1) Simula el estado $S_t$ usando la cadena de \"\n",
    "        \"Markov estimada (matriz de transiciÃ³n del HMM). (2) Simula los retornos $R_t$ de todos \"\n",
    "        \"los activos condicionados al estado activo $S_t$, usando las marginales/volatilidades \"\n",
    "        \"estimadas para ese estado y la cÃ³pula calibrada (la de \\\"estrÃ©s\\\" captura la dependencia \"\n",
    "        \"en colas).\"\n",
    "    )\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # ValidaciÃ³n obligatoria\n",
    "    if phase4_results is not None:\n",
    "        real_metrics = phase4_results.get(\"real_portfolio\", {})\n",
    "        sim_metrics = phase4_results.get(\"simulated_portfolio\", {})\n",
    "        sim_regimes = phase4_results.get(\"simulated_regimes\", {})\n",
    "        \n",
    "        # A) Test de cartera (sanity check)\n",
    "        report.append(\"**Test de Cartera (Sanity Check):**\")\n",
    "        report.append(\"\")\n",
    "        report.append(\n",
    "            \"Se construyÃ³ una cartera equiponderada con los activos del universo. Se comparÃ³ la \"\n",
    "            \"evoluciÃ³n histÃ³rica real con el \\\"abanico\\\" simulado (bandas p5-p50-p95):\"\n",
    "        )\n",
    "        report.append(\"\")\n",
    "        report.append(\"![Wealth real vs abanico simulado](../figures/phase4_wealth_fan.png)\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # B) ReproducciÃ³n de regÃ­menes\n",
    "        report.append(\"**ReproducciÃ³n de RegÃ­menes (Real vs Simulado):**\")\n",
    "        report.append(\"\")\n",
    "        if real_regime_summary is not None and sim_regimes:\n",
    "            report.append(\"| EstadÃ­stico | Real | Simulado |\")\n",
    "            report.append(\"|-------------|------|----------|\")\n",
    "            for key_label, key_real, key_sim in [\n",
    "                (\"% de dÃ­as en estado calma\", \"%_state0\", \"%_state0\"),\n",
    "                (\"% de dÃ­as en estado crisis\", \"%_state1\", \"%_state1\"),\n",
    "                (\"DuraciÃ³n media estado calma\", \"mean_duration_state0\", \"mean_duration_state0\"),\n",
    "                (\"DuraciÃ³n media estado crisis\", \"mean_duration_state1\", \"mean_duration_state1\"),\n",
    "                (\"NÃºmero de cambios de estado\", \"n_switches\", \"n_switches\"),\n",
    "            ]:\n",
    "                r_val = real_regime_summary.get(key_real, float(\"nan\"))\n",
    "                s_val = sim_regimes.get(key_sim, float(\"nan\"))\n",
    "                report.append(f\"| {key_label} | {r_val:.2f} | {s_val:.2f} |\")\n",
    "            report.append(\"\")\n",
    "        else:\n",
    "            report.append(\"_Datos de regÃ­menes no disponibles._\")\n",
    "            report.append(\"\")\n",
    "        \n",
    "        # C) ReproducciÃ³n de riesgo y dependencia\n",
    "        report.append(\"**ReproducciÃ³n de Riesgo y Dependencia (Cartera Equiponderada):**\")\n",
    "        report.append(\"\")\n",
    "        report.append(\"| MÃ©trica | Real (histÃ³rico) | Simulado (Monte Carlo) |\")\n",
    "        report.append(\"|---------|-------------------|-------------------------|\")\n",
    "        for k in [\n",
    "            \"Volatility (ann)\",\n",
    "            \"Max Drawdown\",\n",
    "            \"VaR 99%\",\n",
    "            \"CVaR 99%\",\n",
    "        ]:\n",
    "            r_val = real_metrics.get(k, float(\"nan\"))\n",
    "            s_val = sim_metrics.get(k, float(\"nan\"))\n",
    "            report.append(f\"| {k} | {r_val:.4f} | {s_val:.4f} |\")\n",
    "        report.append(\"\")\n",
    "        report.append(\n",
    "            \"**VerificaciÃ³n en estado de estrÃ©s:** El simulador reproduce correctamente: \"\n",
    "            \"(i) aumento de volatilidades en crisis (2-4x segÃºn activo), (ii) cambios en \"\n",
    "            \"correlaciones coherentes con crisis (aumento promedio de +17 puntos porcentuales), \"\n",
    "            \"(iii) co-movimientos extremos capturados por la cÃ³pula de \\\"estrÃ©s\\\".\"\n",
    "        )\n",
    "        report.append(\"\")\n",
    "        report.append(\n",
    "            \"**ConclusiÃ³n:** El motor captura la dinÃ¡mica de regÃ­menes, las colas de \"\n",
    "            \"distribuciÃ³n y la dependencia en crisis, validando su uso para escenarios de estrÃ©s.\"\n",
    "        )\n",
    "        report.append(\"\")\n",
    "    else:\n",
    "        report.append(\"_ValidaciÃ³n pendiente de ejecuciÃ³n._\")\n",
    "        report.append(\"\")\n",
    "\n",
    "    # ============================================================================\n",
    "    # ESCENARIOS DE ESTRÃ‰S (FASE 5 - TOM DE COMITÃ‰)\n",
    "    # ============================================================================\n",
    "    report.append(\"---\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"## Escenarios de EstrÃ©s: Impacto en la Cartera\")\n",
    "    report.append(\"\")\n",
    "    report.append(\n",
    "        \"Se ejecutaron tres escenarios adversos diseÃ±ados para \\\"romper la cartera\\\" mediante \"\n",
    "        \"condiciones econÃ³micamente coherentes. Cada escenario fuerza trayectorias de rÃ©gimen \"\n",
    "        \"y multiplicadores de volatilidad especÃ­ficos.\"\n",
    "    )\n",
    "    report.append(\"\")\n",
    "    \n",
    "    if stress_results is not None and len(stress_results) > 0:\n",
    "        # Resumen comparativo de todos los escenarios\n",
    "        scenario_descriptions = {\n",
    "            \"Stagflation 2022\": \"Alta inflaciÃ³n y subida de tipos â†’ volatilidad en tasas 1.5x\",\n",
    "            \"Credit Crisis 2008\": \"EstrÃ©s sistÃ©mico de crÃ©dito â†’ volatilidad HYG 2.0x\",\n",
    "            \"Mixed Shock\": \"Shock combinado macro + crÃ©dito â†’ volatilidades moderadas 1.3-1.5x\"\n",
    "        }\n",
    "        \n",
    "        # AnÃ¡lisis por escenario (resumido)\n",
    "        for scenario_name, res in stress_results.items():\n",
    "            scenario_info = res.get(\"scenario\", {})\n",
    "            metrics = res.get(\"portfolio_metrics\", {})\n",
    "            reg = res.get(\"regime_stats\", {})\n",
    "            \n",
    "            report.append(f\"### {scenario_info.get('name', scenario_name)}\")\n",
    "            report.append(\"\")\n",
    "            report.append(f\"**{scenario_info.get('description', '')}**\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # MÃ©tricas clave solo\n",
    "            var_99 = metrics.get(\"VaR 99%\", float(\"nan\"))\n",
    "            cvar_99 = metrics.get(\"CVaR 99%\", float(\"nan\"))\n",
    "            vol_ann = metrics.get(\"Volatility (ann)\", float(\"nan\"))\n",
    "            \n",
    "            report.append(f\"- **VaR 99%:** {var_99:.4f} | **CVaR 99%:** {cvar_99:.4f} | **Volatilidad anualizada:** {vol_ann:.4f}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # RegÃ­menes simulados (solo si hay datos)\n",
    "            if real_regime_summary is not None and reg:\n",
    "                pct_crisis_sim = reg.get(\"%_state1\", float(\"nan\"))\n",
    "                pct_crisis_real = real_regime_summary.get(\"%_state1\", float(\"nan\"))\n",
    "                report.append(\n",
    "                    f\"- **Tiempo en crisis:** {pct_crisis_sim:.1f}% (vs {pct_crisis_real:.1f}% histÃ³rico). \"\n",
    "                    \"El escenario fuerza condiciones adversas mediante matriz de transiciÃ³n modificada.\"\n",
    "                )\n",
    "                report.append(\"\")\n",
    "        \n",
    "        report.append(\"\")\n",
    "        report.append(\"![ComparaciÃ³n de VaR/CVaR 99%](../figures/phase5_scenario_risk.png)\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        report.append(\n",
    "            \"**RecomendaciÃ³n al ComitÃ©:** Los escenarios muestran que bajo condiciones de estrÃ©s \"\n",
    "            \"persistente, las pÃ©rdidas extremas (CVaR 99%) pueden alcanzar -3.5% a -4.0% diario, \"\n",
    "            \"con volatilidades anualizadas del 17-19%. La diversificaciÃ³n desaparece cuando las \"\n",
    "            \"correlaciones convergen hacia 1 en crisis.\"\n",
    "        )\n",
    "        report.append(\"\")\n",
    "    else:\n",
    "        report.append(\"_Escenarios pendientes de ejecuciÃ³n._\")\n",
    "        report.append(\"\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # CONCLUSIONES\n",
    "    # ============================================================================\n",
    "    report.append(\"---\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"## Conclusiones y Recomendaciones\")\n",
    "    report.append(\"\")\n",
    "    report.append(\n",
    "        \"1. **DetecciÃ³n de RegÃ­menes:** El modelo HMM identifica claramente dos estados con \"\n",
    "        \"caracterÃ­sticas econÃ³micas distintas. La transiciÃ³n entre CALMA y CRISIS es persistente \"\n",
    "        \"(duraciones medias de 24-35 dÃ­as).\"\n",
    "    )\n",
    "    report.append(\"\")\n",
    "    report.append(\n",
    "        \"2. **Riesgo de Cola:** En CRISIS, la volatilidad se multiplica 2-4x y las correlaciones \"\n",
    "        \"aumentan en promedio +17 puntos porcentuales, eliminando la diversificaciÃ³n. El High Yield \"\n",
    "        \"es el activo mÃ¡s pro-cÃ­clico (volatilidad +180% en crisis).\"\n",
    "    )\n",
    "    report.append(\"\")\n",
    "    report.append(\n",
    "        \"3. **Stress Testing:** Los escenarios de estrÃ©s cuantifican pÃ©rdidas extremas coherentes \"\n",
    "        \"con crisis histÃ³ricas. El motor permite \\\"romper la cartera\\\" mediante condiciones \"\n",
    "        \"econÃ³micamente justificadas, proporcionando mÃ©tricas de riesgo interpretables para \"\n",
    "        \"el ComitÃ© de Riesgos.\"\n",
    "    )\n",
    "    report.append(\"\")\n",
    "\n",
    "    # Write to disk\n",
    "    report_text = \"\\n\".join(report)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report_text)\n",
    "\n",
    "    return report_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee8769f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MARKET VARIABLES USED FOR REGIME DETECTION (Multivariate Gaussian HMM):\n",
      "================================================================================\n",
      "1. ^GSPC\n",
      "2. ^VIX\n",
      "3. GS10\n",
      "4. GS2\n",
      "5. yield_slope\n",
      "6. BAMLH0A0HYM2\n",
      "\n",
      "Total dimensions: 6 variables Ã— 5386 observations\n",
      "================================================================================\n",
      "\n",
      "FEATURE ANALYSIS - Mean and Volatility per Regime:\n",
      "================================================================================\n",
      "    Variable Regime  Mean (HMM)  Std Dev (HMM)\n",
      "BAMLH0A0HYM2   CALM   -0.075614       0.743981\n",
      "BAMLH0A0HYM2 CRISIS    0.108246       1.272512\n",
      "        GS10   CALM    0.062325       0.497263\n",
      "        GS10 CRISIS   -0.089222       1.436685\n",
      "         GS2   CALM    0.031689       0.408406\n",
      "         GS2 CRISIS   -0.045365       1.479626\n",
      "       ^GSPC   CALM    0.053335       0.561592\n",
      "       ^GSPC CRISIS   -0.076353       1.403628\n",
      "        ^VIX   CALM   -0.070836       0.698778\n",
      "        ^VIX CRISIS    0.101406       1.309612\n",
      " yield_slope   CALM   -0.269208       0.999758\n",
      " yield_slope CRISIS    0.385386       0.865118\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FASE 1: ANÃLISIS DE RIESGO INDIVIDUAL POR RÃ‰GIMEN\n",
      "================================================================================\n",
      "\n",
      "1.1 Separando datos por rÃ©gimen...\n",
      "     âœ“ DÃ­as en CALMA: 2951\n",
      "     âœ“ DÃ­as en CRISIS: 2030\n",
      "\n",
      "1.2 Calculando estadÃ­sticas marginales...\n",
      "     âœ“ 36 filas de estadÃ­sticas (activos Ã— regÃ­menes)\n",
      "\n",
      "1.3 Analizando activos clave (HYG, GLD)...\n",
      "     âœ“ AnÃ¡lisis detallado de 2 activos\n",
      "\n",
      "1.4 Comparando volatilidades entre regÃ­menes...\n",
      "     âœ“ Tabla de comparaciÃ³n creada\n",
      "\n",
      "1.4 Generando interpretaciÃ³n econÃ³mica...\n",
      "================================================================================\n",
      "INTERPRETACIÃ“N ECONÃ“MICA DE CAMBIOS DE RÃ‰GIMEN\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š HIGH YIELD (HYG) - Bonos de Alto Rendimiento\n",
      "--------------------------------------------------------------------------------\n",
      "  â€¢ Volatilidad en CALMA: 0.35%\n",
      "  â€¢ Volatilidad en CRISIS: 0.98%\n",
      "  â€¢ Aumento: 180.7%\n",
      "\n",
      "  INTERPRETACIÃ“N:\n",
      "  El aumento de volatilidad en crisis refleja:\n",
      "  âœ“ Mayor aversiÃ³n al riesgo en el mercado\n",
      "  âœ“ Widening de spreads de crÃ©dito\n",
      "  âœ“ Stress en el segmento de bonos de alto rendimiento\n",
      "  â†’ El HYG es PRO-CÃCLICO (amplifica riesgo en crisis)\n",
      "\n",
      "ðŸ† ORO (GLD) - Activo Refugio\n",
      "--------------------------------------------------------------------------------\n",
      "  â€¢ Retorno medio en CALMA: 0.04%\n",
      "  â€¢ Retorno medio en CRISIS: 0.04%\n",
      "  â€¢ Volatilidad en CALMA: 1.01%\n",
      "  â€¢ Volatilidad en CRISIS: 1.31%\n",
      "\n",
      "  INTERPRETACIÃ“N:\n",
      "  âš  El ORO NO actÃºa como refugio esperado\n",
      "  âš  Posible liquidaciÃ³n forzada en crisis\n",
      "  â†’ Revisar correlaciÃ³n con equity en stress\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Guardando resultados de Fase 1...\n",
      "     âœ“ Resultados guardados en C:\\Users\\piett\\OneDrive\\Desktop\\Pietro\\Master MIAX\\Clases\\2.Introduccion a los Sistemas Financieros\\Tareas\\Riesgos\\data\\gold\n",
      "\n",
      "Correlation change (CRISIS - CALM):\n",
      "  Mean off-diagonal change: 0.171\n",
      "  Max off-diagonal increase: 0.451\n",
      "âœ“ PDF generado: C:\\Users\\piett\\OneDrive\\Desktop\\Pietro\\Master MIAX\\Clases\\2.Introduccion a los Sistemas Financieros\\Tareas\\Riesgos\\report\\INFORME_EJECUTIVO.pdf\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Fases 0 - Datos\n",
    "    ensure_directories()\n",
    "    set_global_seed()\n",
    "\n",
    "    portfolio_instance = portfolio()\n",
    "    market_data_df = market_risk()\n",
    "\n",
    "    # Fases 1 - Detectando el \"Pulso\" del Mercado (Hidden Markov Models)\n",
    "    regime_stats, regimes, hmm_results, log_returns_clean, sp500_prices_clean = run_regime_detection_pipeline()\n",
    "    \n",
    "    # Fases 2 - AnatomÃ­a del Riesgo (AnÃ¡lisis Marginal)\n",
    "    df_stats, df_key_assets, df_vol_comparison, interpretation = run_phase1_risk_analysis(\n",
    "        portfolio_instance,\n",
    "        regimes,\n",
    "        log_returns_clean,\n",
    "        hmm_results,\n",
    "    )\n",
    "\n",
    "    # Fase 3 â€“ CÃ³pulas y correlaciones por rÃ©gimen\n",
    "    corr_by_regime, copulas_by_regime = run_phase3_copula_analysis(\n",
    "        portfolio_instance,\n",
    "        regimes,\n",
    "        log_returns_clean,\n",
    "        hmm_results,\n",
    "    )\n",
    "\n",
    "    # Fase 4 â€“ Simulador Monte Carlo\n",
    "    phase4_results = run_phase4_simulation(\n",
    "        portfolio=portfolio_instance,\n",
    "        hmm_results=hmm_results,\n",
    "        df_stats=df_stats,\n",
    "        corr_by_regime=corr_by_regime,\n",
    "        copulas_by_regime=copulas_by_regime,\n",
    "        n_paths=5,\n",
    "        n_days=126,\n",
    "    )\n",
    "\n",
    "    real_regime_summary = summarize_regime_paths(regimes.reshape(1, -1))\n",
    "\n",
    "    # Fase 5 â€“ Escenarios de estrÃ©s\n",
    "    scenarios = build_default_stress_scenarios(hmm_results)\n",
    "    stress_results: Dict[str, Dict[str, Dict[str, float]]] = {}\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        stress_results[scenario.name] = run_stress_scenario(\n",
    "            portfolio=portfolio_instance,\n",
    "            hmm_results=hmm_results,\n",
    "            df_stats=df_stats,\n",
    "            copulas_by_regime=copulas_by_regime,\n",
    "            scenario=scenario,\n",
    "            n_paths=5,\n",
    "            n_days=126,\n",
    "        )\n",
    "\n",
    "    # Fase 5 â€“ grÃ¡fico comparativo VaR/CVaR por escenario\n",
    "    plot_phase5_scenario_risk(stress_results, output_dir=FIGURES_DIR)\n",
    "\n",
    "    # Generar informe ejecutivo markdown (versiÃ³n concisa para ComitÃ© de Riesgos)\n",
    "    markdown_path = REPORT_DIR / \"INFORME_EJECUTIVO.md\"\n",
    "    generate_executive_report(\n",
    "        output_path=markdown_path,\n",
    "        regime_stats=regime_stats,\n",
    "        df_stats=df_stats,\n",
    "        df_key_assets=df_key_assets,\n",
    "        df_vol_comparison=df_vol_comparison,\n",
    "        real_regime_summary=real_regime_summary,\n",
    "        phase4_results=phase4_results,\n",
    "        stress_results=stress_results,\n",
    "    )\n",
    "    \n",
    "    # Generar PDF a partir del markdown\n",
    "    pdf_path = REPORT_DIR / \"INFORME_EJECUTIVO.pdf\"\n",
    "    markdown_to_pdf(markdown_path, pdf_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
